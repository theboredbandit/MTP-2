{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-DjND7_sk07U",
        "outputId": "e6959cde-a391-4818-e079-2da57c727a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-23.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.40.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
            "Collecting torch==1.13.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torch-1.13.1%2Bcpu-cp310-cp310-linux_x86_64.whl (199.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.14.1+cpu\n",
            "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.14.1%2Bcpu-cp310-cp310-linux_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cpu) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cpu) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cpu) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.14.1+cpu) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cpu) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cpu) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cpu) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.14.1+cpu) (3.4)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.13.1+cpu which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.13.1+cpu which is incompatible.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.13.1+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cpu torchvision-0.14.1+cpu\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autogluon\n",
            "  Downloading autogluon-0.7.0-py3-none-any.whl (9.7 kB)\n",
            "Collecting autogluon.core[all]==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.core-0.7.0-py3-none-any.whl (218 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.3/218.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.features==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.features-0.7.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.tabular[all]==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.tabular-0.7.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.multimodal==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.multimodal-0.7.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.timeseries[all]==0.7.0 (from autogluon)\n",
            "  Downloading autogluon.timeseries-0.7.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.27,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.22.4)\n",
            "Requirement already satisfied: scipy<1.12,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn<1.3,>=1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.2.2)\n",
            "Collecting networkx<3.0,>=2.3 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<1.6,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (1.5.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (2.27.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading boto3-1.26.123-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autogluon.common==0.7.0 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading autogluon.common-0.7.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==0.7.0->autogluon) (0.2.7)\n",
            "Collecting ray[tune]<2.3,>=2.2 (from autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading ray-2.2.0-cp310-cp310-manylinux2014_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<9.6,>=9.3 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema<4.18,>=4.14 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m941.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.4.0,>=0.2.2 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate<0.17,>=0.9 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm<0.7.0,>=0.6.12 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<1.14,>=1.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.13.1+cpu)\n",
            "Requirement already satisfied: torchvision<0.15.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.14.1+cpu)\n",
            "Collecting fairscale<0.4.14,>=0.4.5 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-image<0.20.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
            "Collecting pytorch-lightning<1.10.0,>=1.9.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (1.3)\n",
            "Collecting torchmetrics<0.9.0,>=0.8.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<4.27.0,>=4.23.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n",
            "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-metric-learning<2.0,>=1.3.0 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pytorch_metric_learning-1.7.3-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (3.8.1)\n",
            "Collecting openmim<0.4.0,>0.1.5 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading openmim-0.3.7-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==0.7.0->autogluon) (2.12.2)\n",
            "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Collecting catboost<1.2,>=1.0 (from autogluon.tabular[all]==0.7.0->autogluon)\n",
            "  Downloading catboost-1.1.1-cp310-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lightgbm<3.4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (3.3.5)\n",
            "Requirement already satisfied: xgboost<1.8,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (1.7.5)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==0.7.0->autogluon) (2.7.12)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: statsmodels<0.14,>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==0.7.0->autogluon) (0.13.5)\n",
            "Collecting gluonts<0.13,>=0.12.0 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading gluonts-0.12.7-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ujson<6,>=5 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sktime<0.16,>=0.14 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading sktime-0.15.1-py3-none-any.whl (16.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tbats<2,>=1.1 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading tbats-1.1.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pmdarima<1.9,>=1.8.2 (from autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading pmdarima-1.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==0.7.0->autogluon.core[all]==0.7.0->autogluon) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (23.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.17,>=0.9->autogluon.multimodal==0.7.0->autogluon) (6.0)\n",
            "Collecting botocore<1.30.0,>=1.29.123 (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading botocore-1.29.123-py3-none-any.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3<2,>=1.10->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (0.20.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (1.16.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (2023.4.0)\n",
            "Collecting huggingface-hub>=0.7.0 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19 (from evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.5.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.5.2)\n",
            "Requirement already satisfied: pydantic~=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (1.10.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.13,>=0.12.0->autogluon.timeseries[all]==0.7.0->autogluon) (4.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.7.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.7.0->autogluon) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.7.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.7.0->autogluon) (0.40.0)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.6.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.7.0->autogluon) (2022.10.31)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting colorama (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (13.3.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.8.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<1.6,>=1.4.1->autogluon.core[all]==0.7.0->autogluon) (2022.7.1)\n",
            "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (0.29.34)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima<1.9,>=1.8.2->autogluon.timeseries[all]==0.7.0->autogluon) (1.26.15)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.12.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.20.3)\n",
            "Collecting aiosignal (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv>=20.0.24 (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (1.54.0)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (3.4)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.7.0->autogluon) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.3,>=1.0->autogluon.core[all]==0.7.0->autogluon) (3.1.0)\n",
            "Collecting deprecated>=1.2.13 (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon)\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numba>=0.55 in /usr/local/lib/python3.10/dist-packages (from sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.56.4)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<0.14,>=0.13.0->autogluon.timeseries[all]==0.7.0->autogluon) (0.5.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (2.3.0)\n",
            "Collecting pyDeprecate==0.3.* (from torchmetrics<0.9.0,>=0.8.0->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<4.27.0,>=4.23.0->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==0.7.0->autogluon) (3.0.9)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon) (9.0.0)\n",
            "Collecting aiohttp (from datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (1.14.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (4.11.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55->sktime<0.16,>=0.14->autogluon.timeseries[all]==0.7.0->autogluon) (0.39.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (3.3.0)\n",
            "Collecting distlib<1,>=0.3.6 (from virtualenv>=20.0.24->ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.24->ray[tune]<2.3,>=2.2->autogluon.core[all]==0.7.0->autogluon) (3.3.0)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.7.0->autogluon) (8.2.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (2.14.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m829.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate<0.4.0,>=0.2.2->autogluon.multimodal==0.7.0->autogluon)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->openmim<0.4.0,>0.1.5->autogluon.multimodal==0.7.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.7.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.7.0->autogluon) (0.0.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.7.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==0.7.0->autogluon) (1.7.1)\n",
            "Building wheels for collected packages: fairscale, antlr4-python3-runtime, seqeval\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332130 sha256=898b69854719c7074dc2f4fa9508f2aeeb846104e36a42aa60f3779e800a4ebe\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=13d691966248c71ef82ce2fd792108731d0ccedc5b7705f8543e1a2d9d8c0c43\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6d9fddcea9966c8c496c03e758bd39cb14c6d6c707745ac0ccdc019e0476e94e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built fairscale antlr4-python3-runtime seqeval\n",
            "Installing collected packages: tokenizers, sentencepiece, distlib, antlr4-python3-runtime, xxhash, virtualenv, ujson, tensorboardX, pyDeprecate, Pillow, ordered-set, omegaconf, nptyping, networkx, multidict, lightning-utilities, jsonschema, jmespath, frozenlist, dill, deprecated, colorama, async-timeout, yarl, torchmetrics, responses, pytesseract, multiprocess, model-index, huggingface-hub, fairscale, botocore, aiosignal, accelerate, transformers, timm, seqeval, s3transfer, ray, pytorch-metric-learning, openmim, gluonts, catboost, aiohttp, statsforecast, sktime, pmdarima, nlpaug, boto3, tbats, pytorch-lightning, datasets, autogluon.common, evaluate, autogluon.features, autogluon.core, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "Successfully installed Pillow-9.5.0 accelerate-0.16.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 autogluon-0.7.0 autogluon.common-0.7.0 autogluon.core-0.7.0 autogluon.features-0.7.0 autogluon.multimodal-0.7.0 autogluon.tabular-0.7.0 autogluon.timeseries-0.7.0 boto3-1.26.123 botocore-1.29.123 catboost-1.1.1 colorama-0.4.6 datasets-2.12.0 deprecated-1.2.13 dill-0.3.6 distlib-0.3.6 evaluate-0.3.0 fairscale-0.4.13 frozenlist-1.3.3 gluonts-0.12.7 huggingface-hub-0.14.1 jmespath-1.0.1 jsonschema-4.17.3 lightning-utilities-0.8.0 model-index-0.1.11 multidict-6.0.4 multiprocess-0.70.14 networkx-2.8.8 nlpaug-1.1.11 nptyping-2.4.1 omegaconf-2.2.3 openmim-0.3.7 ordered-set-4.1.0 pmdarima-1.8.5 pyDeprecate-0.3.2 pytesseract-0.3.10 pytorch-lightning-1.9.5 pytorch-metric-learning-1.7.3 ray-2.2.0 responses-0.18.0 s3transfer-0.6.0 sentencepiece-0.1.98 seqeval-1.2.2 sktime-0.15.1 statsforecast-1.4.0 tbats-1.1.3 tensorboardX-2.6 timm-0.6.13 tokenizers-0.13.3 torchmetrics-0.8.2 transformers-4.26.1 ujson-5.7.0 virtualenv-20.23.0 xxhash-3.2.0 yarl-1.9.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U setuptools wheel\n",
        "!pip install torch==1.13.1+cpu torchvision==0.14.1+cpu -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "m52_q2Vik8xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For processed TapData"
      ],
      "metadata": {
        "id": "8eky9G0IgTT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Valence\n",
        "users=[12,13,14,15,16,17,18,19,20,23,25,26,29,32,33,36,37]\n",
        "acc={}\n",
        "for id in users:\n",
        "  dataset = TabularDataset('Tap/Valence/user_' + str(id)+'.csv')\n",
        "  print(\"------- id=\",id)\n",
        "  if(len(dataset)==0):\n",
        "    continue \n",
        "  dataset.drop('Sample id', inplace=True, axis=1) #removing the sample id column \n",
        "  dataset.drop('Within office hour' , inplace=True, axis=1)\n",
        "  dataset.drop('Within office break hour' , inplace=True, axis=1)  \n",
        "  dataset.drop('Duration from office break start' , inplace=True, axis=1)  \n",
        "  dataset.drop('Duration from office break end' , inplace=True, axis=1)    \n",
        "  dataset.drop('Duration from office start' , inplace=True, axis=1)  \n",
        "  dataset.drop('Duration from office end' , inplace=True, axis=1)    \n",
        "  train, test = train_test_split(dataset, test_size=0.25)\n",
        "  label = 'Did the user report?'\n",
        "  train[label].describe()\n",
        "\n",
        "  predictor = TabularPredictor(label=label).fit(train)\n",
        "\n",
        "  #Printing accuracy\n",
        "  y_pred = predictor.predict(test.drop(columns=[label]))\n",
        "  predictor.evaluate(test, silent=True)\n",
        "  acc[id]=predictor.evaluate(test, silent=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9hPDtDUfJF_",
        "outputId": "e1656ab2-9b03-472c-9907-aaf2a2f7bd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loaded data from: Tap/Valence/user_12.csv | Columns = 10 / 10 | Rows = 732 -> 732\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173352/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173352/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    549\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11565.65 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 439, Val Rows: 110\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3091\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2364\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5273\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4455\t = Validation score   (accuracy)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2\t = Validation score   (accuracy)\n",
            "\t1.01s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2091\t = Validation score   (accuracy)\n",
            "\t1.15s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4545\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.1727\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.1909\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 4: early stopping\n",
            "\t0.5182\t = Validation score   (accuracy)\n",
            "\t0.75s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4636\t = Validation score   (accuracy)\n",
            "\t0.26s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5273\t = Validation score   (accuracy)\n",
            "\t1.11s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3636\t = Validation score   (accuracy)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5364\t = Validation score   (accuracy)\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.41s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173352/\")\n",
            "Loaded data from: Tap/Valence/user_13.csv | Columns = 10 / 10 | Rows = 642 -> 642\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173403/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173403/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    481\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11588.41 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 384, Val Rows: 97\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3711\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2371\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5052\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.433\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2371\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2577\t = Validation score   (accuracy)\n",
            "\t0.85s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4845\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2165\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2371\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5464\t = Validation score   (accuracy)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.3608\t = Validation score   (accuracy)\n",
            "\t0.16s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5258\t = Validation score   (accuracy)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4536\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5464\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.79s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173403/\")\n",
            "Loaded data from: Tap/Valence/user_14.csv | Columns = 10 / 10 | Rows = 170 -> 170\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173411/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173411/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    127\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11588.87 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 101, Val Rows: 26\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3462\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1154\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.25s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.24s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2692\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2692\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4615\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2308\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.1923\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 5: early stopping\n",
            "\t0.5769\t = Validation score   (accuracy)\n",
            "\t0.85s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.3077\t = Validation score   (accuracy)\n",
            "\t0.18s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.6154\t = Validation score   (accuracy)\n",
            "\t0.3s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6154\t = Validation score   (accuracy)\n",
            "\t1.11s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.72s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173411/\")\n",
            "Loaded data from: Tap/Valence/user_15.csv | Columns = 10 / 10 | Rows = 784 -> 784\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173418/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173418/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    588\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11584.32 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 470, Val Rows: 118\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2627\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2288\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5169\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5169\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2797\t = Validation score   (accuracy)\n",
            "\t1.06s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2627\t = Validation score   (accuracy)\n",
            "\t1.25s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4492\t = Validation score   (accuracy)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2966\t = Validation score   (accuracy)\n",
            "\t0.94s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2881\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5593\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4153\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5169\t = Validation score   (accuracy)\n",
            "\t1.12s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5169\t = Validation score   (accuracy)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5593\t = Validation score   (accuracy)\n",
            "\t1.25s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.83s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173418/\")\n",
            "Loaded data from: Tap/Valence/user_16.csv | Columns = 10 / 10 | Rows = 1150 -> 1150\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173429/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173429/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    862\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11587.28 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 689, Val Rows: 173\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3468\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2543\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4971\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.3931\t = Validation score   (accuracy)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3006\t = Validation score   (accuracy)\n",
            "\t0.78s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3006\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4855\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2543\t = Validation score   (accuracy)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2543\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.5318\t = Validation score   (accuracy)\n",
            "\t0.75s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4277\t = Validation score   (accuracy)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5087\t = Validation score   (accuracy)\n",
            "\t1.07s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3642\t = Validation score   (accuracy)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5434\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.45s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173429/\")\n",
            "Loaded data from: Tap/Valence/user_17.csv | Columns = 10 / 10 | Rows = 0 -> 0\n",
            "Loaded data from: Tap/Valence/user_18.csv | Columns = 10 / 10 | Rows = 0 -> 0\n",
            "Loaded data from: Tap/Valence/user_19.csv | Columns = 10 / 10 | Rows = 239 -> 239\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173437/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173437/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    179\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11582.23 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 17\n",
            "------- id= 18\n",
            "------- id= 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 143, Val Rows: 36\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.4167\t = Validation score   (accuracy)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2778\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5833\t = Validation score   (accuracy)\n",
            "\t0.29s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5556\t = Validation score   (accuracy)\n",
            "\t0.25s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.25\t = Validation score   (accuracy)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2778\t = Validation score   (accuracy)\n",
            "\t0.9s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.5278\t = Validation score   (accuracy)\n",
            "\t0.48s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.25\t = Validation score   (accuracy)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2778\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 6: early stopping\n",
            "\t0.5833\t = Validation score   (accuracy)\n",
            "\t1.9s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.3889\t = Validation score   (accuracy)\n",
            "\t0.21s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5556\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5833\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5833\t = Validation score   (accuracy)\n",
            "\t1.24s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 9.51s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173437/\")\n",
            "Loaded data from: Tap/Valence/user_20.csv | Columns = 10 / 10 | Rows = 208 -> 208\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173447/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173447/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    156\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11580.03 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 124, Val Rows: 32\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.25\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0938\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5312\t = Validation score   (accuracy)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5312\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3125\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3125\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4375\t = Validation score   (accuracy)\n",
            "\t0.48s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2812\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2812\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.5625\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.12s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5625\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5312\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5625\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.45s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173447/\")\n",
            "Loaded data from: Tap/Valence/user_23.csv | Columns = 10 / 10 | Rows = 814 -> 814\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173455/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173455/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    610\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11581.94 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 488, Val Rows: 122\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3525\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2049\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5082\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4672\t = Validation score   (accuracy)\n",
            "\t0.3s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2213\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2295\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.3689\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2213\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2295\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5328\t = Validation score   (accuracy)\n",
            "\t0.53s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.377\t = Validation score   (accuracy)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t1.22s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3689\t = Validation score   (accuracy)\n",
            "\t0.58s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.541\t = Validation score   (accuracy)\n",
            "\t1.19s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.38s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173455/\")\n",
            "Loaded data from: Tap/Valence/user_25.csv | Columns = 10 / 10 | Rows = 271 -> 271\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173503/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173503/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    203\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11589.48 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 162, Val Rows: 41\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3171\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.1951\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5122\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5122\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2195\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2683\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.3659\t = Validation score   (accuracy)\n",
            "\t0.52s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.122\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.122\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 2: early stopping\n",
            "\t0.5122\t = Validation score   (accuracy)\n",
            "\t1.83s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.3171\t = Validation score   (accuracy)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5122\t = Validation score   (accuracy)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5122\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5122\t = Validation score   (accuracy)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 9.52s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173503/\")\n",
            "Loaded data from: Tap/Valence/user_26.csv | Columns = 10 / 10 | Rows = 1600 -> 1600\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173513/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173513/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    1200\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11588.17 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 960, Val Rows: 240\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.3667\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2542\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5083\t = Validation score   (accuracy)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.525\t = Validation score   (accuracy)\n",
            "\t0.53s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2875\t = Validation score   (accuracy)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2833\t = Validation score   (accuracy)\n",
            "\t1.11s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4708\t = Validation score   (accuracy)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2792\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2708\t = Validation score   (accuracy)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 2: early stopping\n",
            "\t0.5292\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5042\t = Validation score   (accuracy)\n",
            "\t0.21s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5375\t = Validation score   (accuracy)\n",
            "\t1.65s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4458\t = Validation score   (accuracy)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5458\t = Validation score   (accuracy)\n",
            "\t0.93s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.44s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173513/\")\n",
            "Loaded data from: Tap/Valence/user_29.csv | Columns = 10 / 10 | Rows = 600 -> 600\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173523/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173523/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    450\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11588.97 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 360, Val Rows: 90\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.4556\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2444\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.5556\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5333\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2111\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2\t = Validation score   (accuracy)\n",
            "\t1.07s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2444\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2444\t = Validation score   (accuracy)\n",
            "\t0.89s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5556\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4111\t = Validation score   (accuracy)\n",
            "\t0.26s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5556\t = Validation score   (accuracy)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5333\t = Validation score   (accuracy)\n",
            "\t0.68s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5889\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.27s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173523/\")\n",
            "Loaded data from: Tap/Valence/user_32.csv | Columns = 10 / 10 | Rows = 140 -> 140\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173534/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173534/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    105\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11583.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 84, Val Rows: 21\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3333\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2381\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5714\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5238\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.381\t = Validation score   (accuracy)\n",
            "\t0.47s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2381\t = Validation score   (accuracy)\n",
            "\t0.84s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2381\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 6: early stopping\n",
            "\t0.619\t = Validation score   (accuracy)\n",
            "\t1.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.381\t = Validation score   (accuracy)\n",
            "\t0.21s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5714\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4286\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.619\t = Validation score   (accuracy)\n",
            "\t1.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.96s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173534/\")\n",
            "Loaded data from: Tap/Valence/user_33.csv | Columns = 10 / 10 | Rows = 992 -> 992\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173543/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173543/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    744\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11584.13 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 595, Val Rows: 149\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2953\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2013\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4631\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4631\t = Validation score   (accuracy)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2081\t = Validation score   (accuracy)\n",
            "\t1.01s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.1879\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4832\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2081\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.1946\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 8: early stopping\n",
            "\t0.5302\t = Validation score   (accuracy)\n",
            "\t1.15s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4027\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5034\t = Validation score   (accuracy)\n",
            "\t1.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4295\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5436\t = Validation score   (accuracy)\n",
            "\t1.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.82s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173543/\")\n",
            "Loaded data from: Tap/Valence/user_36.csv | Columns = 10 / 10 | Rows = 80 -> 80\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173554/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173554/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    60\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11585.94 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.07s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 48, Val Rows: 12\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.0833\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.0\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.1667\t = Validation score   (accuracy)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.1667\t = Validation score   (accuracy)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.3333\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.0833\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.0833\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.75\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.3333\t = Validation score   (accuracy)\n",
            "\t0.15s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.3s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.75\t = Validation score   (accuracy)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.2s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173554/\")\n",
            "Loaded data from: Tap/Valence/user_37.csv | Columns = 10 / 10 | Rows = 464 -> 464\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_173602/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_173602/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    348\n",
            "Train Data Columns: 2\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11587.11 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 2 | ['Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t2 features in original data used to generate 2 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 278, Val Rows: 70\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.3\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.5571\t = Validation score   (accuracy)\n",
            "\t0.29s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5143\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3143\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3286\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.5857\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3143\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 4: early stopping\n",
            "\t0.5571\t = Validation score   (accuracy)\n",
            "\t0.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4714\t = Validation score   (accuracy)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.6143\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5143\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6143\t = Validation score   (accuracy)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.72s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_173602/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Valence\n",
        "for uid in acc:\n",
        "  print(uid,': ')\n",
        "  print(acc[uid])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7BgFh8Qi0q7",
        "outputId": "6dfb8e8b-8fe6-4802-d11d-831c0d9df925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 : \n",
            "{'accuracy': 0.4262295081967213, 'balanced_accuracy': 0.4261825131390349, 'mcc': -0.14765261125544063, 'roc_auc': 0.42827281414237933, 'f1': 0.419889502762431, 'precision': 0.4222222222222222, 'recall': 0.4175824175824176}\n",
            "13 : \n",
            "{'accuracy': 0.4472049689440994, 'balanced_accuracy': 0.44372294372294374, 'mcc': -0.11382835065264445, 'roc_auc': 0.4366110080395794, 'f1': 0.4971751412429379, 'precision': 0.4731182795698925, 'recall': 0.5238095238095238}\n",
            "14 : \n",
            "{'accuracy': 0.46511627906976744, 'balanced_accuracy': 0.46739130434782605, 'mcc': -0.06521739130434782, 'roc_auc': 0.45434782608695656, 'f1': 0.46511627906976744, 'precision': 0.5, 'recall': 0.43478260869565216}\n",
            "15 : \n",
            "{'accuracy': 0.46938775510204084, 'balanced_accuracy': 0.4837962962962963, 'mcc': -0.033640559489972126, 'roc_auc': 0.47464225589225584, 'f1': 0.5140186915887851, 'precision': 0.4365079365079365, 'recall': 0.625}\n",
            "16 : \n",
            "{'accuracy': 0.4791666666666667, 'balanced_accuracy': 0.47745358090185674, 'mcc': -0.05182972815707637, 'roc_auc': 0.4563781046539668, 'f1': 0.3055555555555556, 'precision': 0.4520547945205479, 'recall': 0.23076923076923078}\n",
            "19 : \n",
            "{'accuracy': 0.36666666666666664, 'balanced_accuracy': 0.4342857142857143, 'mcc': -0.23443770806130776, 'roc_auc': 0.3211428571428572, 'f1': 0.049999999999999996, 'precision': 0.2, 'recall': 0.02857142857142857}\n",
            "20 : \n",
            "{'accuracy': 0.36538461538461536, 'balanced_accuracy': 0.5, 'mcc': 0.0, 'roc_auc': 0.44816586921850077, 'f1': 0.5352112676056338, 'precision': 0.36538461538461536, 'recall': 1.0}\n",
            "23 : \n",
            "{'accuracy': 0.47549019607843135, 'balanced_accuracy': 0.491817481709665, 'mcc': -0.029582691662949367, 'roc_auc': 0.47217943781286104, 'f1': 0.6245614035087719, 'precision': 0.47593582887700536, 'recall': 0.9081632653061225}\n",
            "25 : \n",
            "{'accuracy': 0.45588235294117646, 'balanced_accuracy': 0.5, 'mcc': 0.0, 'roc_auc': 0.35701830863121187, 'f1': 0.6262626262626263, 'precision': 0.45588235294117646, 'recall': 1.0}\n",
            "26 : \n",
            "{'accuracy': 0.505, 'balanced_accuracy': 0.5164622984528198, 'mcc': 0.036133201897096186, 'roc_auc': 0.4962511597582688, 'f1': 0.5805084745762711, 'precision': 0.4840989399293286, 'recall': 0.7248677248677249}\n",
            "29 : \n",
            "{'accuracy': 0.38, 'balanced_accuracy': 0.42631964809384165, 'mcc': -0.17517372578356546, 'roc_auc': 0.4276026392961877, 'f1': 0.48044692737430167, 'precision': 0.36752136752136755, 'recall': 0.6935483870967742}\n",
            "32 : \n",
            "{'accuracy': 0.4, 'balanced_accuracy': 0.40522875816993464, 'mcc': -0.20406349327836207, 'roc_auc': 0.40522875816993464, 'f1': 0.48780487804878053, 'precision': 0.4166666666666667, 'recall': 0.5882352941176471}\n",
            "33 : \n",
            "{'accuracy': 0.4637096774193548, 'balanced_accuracy': 0.46544543502310143, 'mcc': -0.06982852465026082, 'roc_auc': 0.4193401444654129, 'f1': 0.494296577946768, 'precision': 0.45774647887323944, 'recall': 0.5371900826446281}\n",
            "36 : \n",
            "{'accuracy': 0.25, 'balanced_accuracy': 0.25, 'mcc': -0.4923659639173309, 'roc_auc': 0.21874999999999997, 'f1': 0.2105263157894737, 'precision': 0.18181818181818182, 'recall': 0.25}\n",
            "37 : \n",
            "{'accuracy': 0.4224137931034483, 'balanced_accuracy': 0.453125, 'mcc': -0.11693850651410916, 'roc_auc': 0.38731971153846156, 'f1': 0.5379310344827586, 'precision': 0.41935483870967744, 'recall': 0.75}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Arousal\n",
        "users=[12,13,14,15,16,17,18,19,20,23,25,26,29,32,33,36,37]\n",
        "acc={}\n",
        "for id in users:\n",
        "  dataset = TabularDataset('Tap/Arousal/user_' + str(id)+'.csv')\n",
        "  print(\"------- id=\",id)\n",
        "  if(len(dataset)==0):\n",
        "    continue \n",
        "  dataset.drop('Sample id', inplace=True, axis=1) #removing the sample id column \n",
        "  dataset.drop('Within office hour' , inplace=True, axis=1)\n",
        "  dataset.drop('Within office break hour' , inplace=True, axis=1)  \n",
        "  dataset.drop('Duration from office break start' , inplace=True, axis=1)  \n",
        "  dataset.drop('Duration from office break end' , inplace=True, axis=1)    \n",
        "  train, test = train_test_split(dataset, test_size=0.25)\n",
        "  label = 'Did the user report?'\n",
        "  train[label].describe()\n",
        "\n",
        "  predictor = TabularPredictor(label=label).fit(train)\n",
        "\n",
        "  #Printing accuracy\n",
        "  y_pred = predictor.predict(test.drop(columns=[label]))\n",
        "  predictor.evaluate(test, silent=True)\n",
        "  acc[id]=predictor.evaluate(test, silent=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxv35Y2wma1s",
        "outputId": "656fad64-b4c0-4870-da53-5163f1493307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loaded data from: Tap/Arousal/user_12.csv | Columns = 10 / 10 | Rows = 766 -> 766\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172015/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172015/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    574\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11649.44 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 459, Val Rows: 115\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3826\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.3217\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5043\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4522\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3565\t = Validation score   (accuracy)\n",
            "\t1.14s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3391\t = Validation score   (accuracy)\n",
            "\t1.39s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4609\t = Validation score   (accuracy)\n",
            "\t0.92s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.3478\t = Validation score   (accuracy)\n",
            "\t1.0s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3391\t = Validation score   (accuracy)\n",
            "\t1.0s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 6: early stopping\n",
            "\t0.513\t = Validation score   (accuracy)\n",
            "\t0.78s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5043\t = Validation score   (accuracy)\n",
            "\t0.36s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5304\t = Validation score   (accuracy)\n",
            "\t1.93s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4174\t = Validation score   (accuracy)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5478\t = Validation score   (accuracy)\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 12.09s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172015/\")\n",
            "Loaded data from: Tap/Arousal/user_13.csv | Columns = 10 / 10 | Rows = 624 -> 624\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172027/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172027/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    468\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11641.77 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 374, Val Rows: 94\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3723\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2234\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4468\t = Validation score   (accuracy)\n",
            "\t0.36s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4043\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3085\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3085\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4787\t = Validation score   (accuracy)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2766\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2872\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.5532\t = Validation score   (accuracy)\n",
            "\t0.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4574\t = Validation score   (accuracy)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.4894\t = Validation score   (accuracy)\n",
            "\t0.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4362\t = Validation score   (accuracy)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5532\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.46s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172027/\")\n",
            "Loaded data from: Tap/Arousal/user_14.csv | Columns = 10 / 10 | Rows = 976 -> 976\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172035/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172035/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    732\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11640.51 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 585, Val Rows: 147\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3741\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2381\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.483\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.483\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3605\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3673\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.483\t = Validation score   (accuracy)\n",
            "\t0.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.3265\t = Validation score   (accuracy)\n",
            "\t0.84s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3333\t = Validation score   (accuracy)\n",
            "\t0.99s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 2: early stopping\n",
            "\t0.517\t = Validation score   (accuracy)\n",
            "\t0.96s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5238\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5102\t = Validation score   (accuracy)\n",
            "\t1.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4762\t = Validation score   (accuracy)\n",
            "\t0.93s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5306\t = Validation score   (accuracy)\n",
            "\t1.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.81s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172035/\")\n",
            "Loaded data from: Tap/Arousal/user_15.csv | Columns = 10 / 10 | Rows = 798 -> 798\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172046/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172046/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    598\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11640.4 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 478, Val Rows: 120\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3167\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2167\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.525\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.525\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2583\t = Validation score   (accuracy)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2333\t = Validation score   (accuracy)\n",
            "\t1.43s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4083\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2167\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.225\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.525\t = Validation score   (accuracy)\n",
            "\t0.46s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5333\t = Validation score   (accuracy)\n",
            "\t0.75s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.425\t = Validation score   (accuracy)\n",
            "\t0.5s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5417\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 9.48s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172046/\")\n",
            "Loaded data from: Tap/Arousal/user_16.csv | Columns = 10 / 10 | Rows = 1218 -> 1218\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172055/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172055/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    913\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11646.81 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 730, Val Rows: 183\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3607\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2787\t = Validation score   (accuracy)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5246\t = Validation score   (accuracy)\n",
            "\t0.29s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4973\t = Validation score   (accuracy)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3333\t = Validation score   (accuracy)\n",
            "\t0.99s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3388\t = Validation score   (accuracy)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4754\t = Validation score   (accuracy)\n",
            "\t0.57s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.3224\t = Validation score   (accuracy)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3279\t = Validation score   (accuracy)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5082\t = Validation score   (accuracy)\n",
            "\t1.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4863\t = Validation score   (accuracy)\n",
            "\t0.39s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5027\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4262\t = Validation score   (accuracy)\n",
            "\t1.19s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.541\t = Validation score   (accuracy)\n",
            "\t1.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.29s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172055/\")\n",
            "Loaded data from: Tap/Arousal/user_17.csv | Columns = 10 / 10 | Rows = 814 -> 814\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172107/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172107/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    610\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11639.48 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 488, Val Rows: 122\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2787\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1639\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5082\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4836\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3115\t = Validation score   (accuracy)\n",
            "\t1.15s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3279\t = Validation score   (accuracy)\n",
            "\t1.41s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4672\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2869\t = Validation score   (accuracy)\n",
            "\t0.98s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3197\t = Validation score   (accuracy)\n",
            "\t1.04s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.5328\t = Validation score   (accuracy)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.459\t = Validation score   (accuracy)\n",
            "\t0.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.418\t = Validation score   (accuracy)\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5492\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.1s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172107/\")\n",
            "Loaded data from: Tap/Arousal/user_18.csv | Columns = 10 / 10 | Rows = 50 -> 50\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172117/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172117/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    37\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11647.09 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 29, Val Rows: 8\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.625\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.24s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.125\t = Validation score   (accuracy)\n",
            "\t0.59s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.125\t = Validation score   (accuracy)\n",
            "\t0.59s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.625\t = Validation score   (accuracy)\n",
            "\t0.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.25\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.375\t = Validation score   (accuracy)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.2s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.15s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.24s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.625\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 5.14s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172117/\")\n",
            "Loaded data from: Tap/Arousal/user_19.csv | Columns = 10 / 10 | Rows = 549 -> 549\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172122/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172122/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    411\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11646.2 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 328, Val Rows: 83\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3494\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2289\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.506\t = Validation score   (accuracy)\n",
            "\t0.26s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.3976\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3012\t = Validation score   (accuracy)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3012\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.3735\t = Validation score   (accuracy)\n",
            "\t0.92s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.3012\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3373\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.4819\t = Validation score   (accuracy)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4458\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.506\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4096\t = Validation score   (accuracy)\n",
            "\t0.59s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.506\t = Validation score   (accuracy)\n",
            "\t1.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 9.44s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172122/\")\n",
            "Loaded data from: Tap/Arousal/user_20.csv | Columns = 10 / 10 | Rows = 474 -> 474\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172132/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172132/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    355\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11639.7 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 284, Val Rows: 71\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3239\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1831\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.3944\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.3521\t = Validation score   (accuracy)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2535\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2535\t = Validation score   (accuracy)\n",
            "\t1.08s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.3662\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2254\t = Validation score   (accuracy)\n",
            "\t0.89s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2254\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.493\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4507\t = Validation score   (accuracy)\n",
            "\t0.2s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.507\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.2958\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5493\t = Validation score   (accuracy)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.55s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172132/\")\n",
            "Loaded data from: Tap/Arousal/user_23.csv | Columns = 10 / 10 | Rows = 768 -> 768\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172140/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172140/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    576\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11640.9 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 460, Val Rows: 116\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3103\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2328\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.5172\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5172\t = Validation score   (accuracy)\n",
            "\t0.3s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.1983\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2155\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.18s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4224\t = Validation score   (accuracy)\n",
            "\t0.66s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.181\t = Validation score   (accuracy)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2155\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4138\t = Validation score   (accuracy)\n",
            "\t0.23s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5172\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5172\t = Validation score   (accuracy)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5172\t = Validation score   (accuracy)\n",
            "\t1.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.74s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172140/\")\n",
            "Loaded data from: Tap/Arousal/user_25.csv | Columns = 10 / 10 | Rows = 303 -> 303\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172149/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172149/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    227\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11645.01 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 181, Val Rows: 46\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2826\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.1522\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5217\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5217\t = Validation score   (accuracy)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2391\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2609\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4348\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2609\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2391\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 2: early stopping\n",
            "\t0.587\t = Validation score   (accuracy)\n",
            "\t1.85s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.413\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4783\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.587\t = Validation score   (accuracy)\n",
            "\t1.24s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.14s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172149/\")\n",
            "Loaded data from: Tap/Arousal/user_26.csv | Columns = 10 / 10 | Rows = 1614 -> 1614\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172200/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172200/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    1210\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11641.86 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 968, Val Rows: 242\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3554\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2397\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5041\t = Validation score   (accuracy)\n",
            "\t0.47s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4463\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3099\t = Validation score   (accuracy)\n",
            "\t1.06s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3099\t = Validation score   (accuracy)\n",
            "\t1.33s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4421\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.3182\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3017\t = Validation score   (accuracy)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.5083\t = Validation score   (accuracy)\n",
            "\t0.9s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4628\t = Validation score   (accuracy)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.4917\t = Validation score   (accuracy)\n",
            "\t1.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4215\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5165\t = Validation score   (accuracy)\n",
            "\t1.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.07s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172200/\")\n",
            "Loaded data from: Tap/Arousal/user_29.csv | Columns = 10 / 10 | Rows = 700 -> 700\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172211/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172211/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    525\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11638.85 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.0s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.08s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 420, Val Rows: 105\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3524\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5238\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5048\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3238\t = Validation score   (accuracy)\n",
            "\t1.12s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2571\t = Validation score   (accuracy)\n",
            "\t1.35s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4571\t = Validation score   (accuracy)\n",
            "\t1.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2667\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2381\t = Validation score   (accuracy)\n",
            "\t0.96s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5048\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4857\t = Validation score   (accuracy)\n",
            "\t0.37s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5238\t = Validation score   (accuracy)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5048\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5333\t = Validation score   (accuracy)\n",
            "\t1.3s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 11.11s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172211/\")\n",
            "Loaded data from: Tap/Arousal/user_32.csv | Columns = 10 / 10 | Rows = 146 -> 146\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172222/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172222/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    109\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11642.0 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.1s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 87, Val Rows: 22\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3182\t = Validation score   (accuracy)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.3182\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5455\t = Validation score   (accuracy)\n",
            "\t0.36s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5909\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3182\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.04s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3182\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2727\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.3182\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 4: early stopping\n",
            "\t0.5909\t = Validation score   (accuracy)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5455\t = Validation score   (accuracy)\n",
            "\t0.12s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5455\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5455\t = Validation score   (accuracy)\n",
            "\t0.26s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.6818\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.32s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172222/\")\n",
            "Loaded data from: Tap/Arousal/user_33.csv | Columns = 10 / 10 | Rows = 988 -> 988\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172229/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172229/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    741\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11641.38 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 592, Val Rows: 149\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.3423\t = Validation score   (accuracy)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2282\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5101\t = Validation score   (accuracy)\n",
            "\t0.28s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5101\t = Validation score   (accuracy)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2617\t = Validation score   (accuracy)\n",
            "\t0.88s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.255\t = Validation score   (accuracy)\n",
            "\t1.0s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.443\t = Validation score   (accuracy)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2752\t = Validation score   (accuracy)\n",
            "\t0.71s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2685\t = Validation score   (accuracy)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5101\t = Validation score   (accuracy)\n",
            "\t0.86s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4631\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5436\t = Validation score   (accuracy)\n",
            "\t1.91s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.4832\t = Validation score   (accuracy)\n",
            "\t0.92s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.557\t = Validation score   (accuracy)\n",
            "\t1.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.94s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172229/\")\n",
            "Loaded data from: Tap/Arousal/user_36.csv | Columns = 10 / 10 | Rows = 94 -> 94\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172240/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172240/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    70\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11639.74 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.0 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.11s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 56, Val Rows: 14\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.3571\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.2143\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2857\t = Validation score   (accuracy)\n",
            "\t0.78s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4286\t = Validation score   (accuracy)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5714\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5714\t = Validation score   (accuracy)\n",
            "\t0.81s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 7.36s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172240/\")\n",
            "Loaded data from: Tap/Arousal/user_37.csv | Columns = 10 / 10 | Rows = 468 -> 468\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_172247/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_172247/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    351\n",
            "Train Data Columns: 4\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['Yes', 'No']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11640.78 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 4 | ['Duration from office start', 'Duration from office end', 'Elapsed time from last reported 0', 'Elapsed time from last reported 1']\n",
            "\t0.1s = Fit runtime\n",
            "\t4 features in original data used to generate 4 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.09s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 280, Val Rows: 71\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2817\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.1831\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.493\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.3944\t = Validation score   (accuracy)\n",
            "\t0.27s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2535\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.05s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2535\t = Validation score   (accuracy)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4225\t = Validation score   (accuracy)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2254\t = Validation score   (accuracy)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2254\t = Validation score   (accuracy)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.493\t = Validation score   (accuracy)\n",
            "\t0.41s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4507\t = Validation score   (accuracy)\n",
            "\t0.22s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.507\t = Validation score   (accuracy)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3944\t = Validation score   (accuracy)\n",
            "\t0.36s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.507\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 6.72s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_172247/\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Arousal\n",
        "for uid in acc:\n",
        "  print(uid,': ')\n",
        "  print(acc[uid])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbTQRTdbr_2-",
        "outputId": "32b5540d-1405-4dd9-84cf-dc27cf0a78f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 : \n",
            "{'accuracy': 0.4166666666666667, 'balanced_accuracy': 0.4143478260869565, 'mcc': -0.172091785773736, 'roc_auc': 0.4010869565217391, 'f1': 0.4563106796116505, 'precision': 0.44339622641509435, 'recall': 0.47}\n",
            "13 : \n",
            "{'accuracy': 0.4935897435897436, 'balanced_accuracy': 0.4935897435897436, 'mcc': -0.019600308903302492, 'roc_auc': 0.4367192636423406, 'f1': 0.6325581395348837, 'precision': 0.49635036496350365, 'recall': 0.8717948717948718}\n",
            "14 : \n",
            "{'accuracy': 0.38524590163934425, 'balanced_accuracy': 0.39548365352207615, 'mcc': -0.2245196687234332, 'roc_auc': 0.36450960566228513, 'f1': 0.46808510638297873, 'precision': 0.39520958083832336, 'recall': 0.5739130434782609}\n",
            "15 : \n",
            "{'accuracy': 0.43, 'balanced_accuracy': 0.46236559139784944, 'mcc': -0.20427761564391175, 'roc_auc': 0.39161893277057586, 'f1': 0.6013986013986014, 'precision': 0.44559585492227977, 'recall': 0.9247311827956989}\n",
            "16 : \n",
            "{'accuracy': 0.4098360655737705, 'balanced_accuracy': 0.40990797282188013, 'mcc': -0.18019955339324376, 'roc_auc': 0.3893523694848198, 'f1': 0.411764705882353, 'precision': 0.4064516129032258, 'recall': 0.41721854304635764}\n",
            "17 : \n",
            "{'accuracy': 0.46078431372549017, 'balanced_accuracy': 0.47805159799768965, 'mcc': -0.09320895410803898, 'roc_auc': 0.4682325760492877, 'f1': 0.6206896551724138, 'precision': 0.46875, 'recall': 0.9183673469387755}\n",
            "18 : \n",
            "{'accuracy': 0.15384615384615385, 'balanced_accuracy': 0.15476190476190477, 'mcc': -0.6904761904761905, 'roc_auc': 0.14285714285714288, 'f1': 0.15384615384615383, 'precision': 0.14285714285714285, 'recall': 0.16666666666666666}\n",
            "19 : \n",
            "{'accuracy': 0.4855072463768116, 'balanced_accuracy': 0.5, 'mcc': 0.0, 'roc_auc': 0.4041412655034686, 'f1': 0.6536585365853659, 'precision': 0.4855072463768116, 'recall': 1.0}\n",
            "20 : \n",
            "{'accuracy': 0.5042016806722689, 'balanced_accuracy': 0.5035310734463276, 'mcc': 0.0071536688127848014, 'roc_auc': 0.5031073446327684, 'f1': 0.5426356589147286, 'precision': 0.5072463768115942, 'recall': 0.5833333333333334}\n",
            "23 : \n",
            "{'accuracy': 0.4427083333333333, 'balanced_accuracy': 0.5, 'mcc': 0.0, 'roc_auc': 0.4446948873007147, 'f1': 0.6137184115523465, 'precision': 0.4427083333333333, 'recall': 1.0}\n",
            "25 : \n",
            "{'accuracy': 0.5, 'balanced_accuracy': 0.5140056022408963, 'mcc': 0.028873288694801547, 'roc_auc': 0.607843137254902, 'f1': 0.4571428571428571, 'precision': 0.5714285714285714, 'recall': 0.38095238095238093}\n",
            "26 : \n",
            "{'accuracy': 0.47277227722772275, 'balanced_accuracy': 0.4781505186493048, 'mcc': -0.04853309519197618, 'roc_auc': 0.45226709826136, 'f1': 0.5626283367556468, 'precision': 0.4724137931034483, 'recall': 0.6954314720812182}\n",
            "29 : \n",
            "{'accuracy': 0.3942857142857143, 'balanced_accuracy': 0.39575163398692814, 'mcc': -0.20965093390425973, 'roc_auc': 0.3773856209150327, 'f1': 0.4175824175824176, 'precision': 0.3917525773195876, 'recall': 0.4470588235294118}\n",
            "32 : \n",
            "{'accuracy': 0.3783783783783784, 'balanced_accuracy': 0.4348484848484848, 'mcc': -0.16334349292548103, 'roc_auc': 0.35757575757575755, 'f1': 0.4888888888888889, 'precision': 0.36666666666666664, 'recall': 0.7333333333333333}\n",
            "33 : \n",
            "{'accuracy': 0.46153846153846156, 'balanced_accuracy': 0.47101449275362317, 'mcc': -0.06023143906514035, 'roc_auc': 0.4572463768115942, 'f1': 0.5128205128205128, 'precision': 0.4430379746835443, 'recall': 0.6086956521739131}\n",
            "36 : \n",
            "{'accuracy': 0.2916666666666667, 'balanced_accuracy': 0.30419580419580416, 'mcc': -0.4139186771923578, 'roc_auc': 0.26573426573426573, 'f1': 0.3703703703703703, 'precision': 0.3125, 'recall': 0.45454545454545453}\n",
            "37 : \n",
            "{'accuracy': 0.4444444444444444, 'balanced_accuracy': 0.4548245614035088, 'mcc': -0.1547377049558979, 'roc_auc': 0.42807017543859655, 'f1': 0.6012269938650306, 'precision': 0.46226415094339623, 'recall': 0.8596491228070176}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#For processed Selfi data"
      ],
      "metadata": {
        "id": "CzCSc_4pgYTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Valence\n",
        "users=[12,13,14,15,16,17,18,19,20,23,25,26,29,32,33]\n",
        "acc={}\n",
        "for id in users:\n",
        "  dataset = TabularDataset('Selfi/Valence/user_' + str(id)+'.csv')\n",
        "  print(\"------- id=\",id)\n",
        "  if(len(dataset)==0):\n",
        "    continue \n",
        "  dataset.drop('Sample id', inplace=True, axis=1) #removing the sample id column \n",
        "  train= dataset\n",
        "  dataset2=TabularDataset('Tap/Valence/user_' + str(id)+'.csv')\n",
        "  temp, test=train_test_split(dataset, test_size=0.50)\n",
        "  label = 'Did the user report?'\n",
        "  train[label].describe()\n",
        "\n",
        "  predictor = TabularPredictor(label=label).fit(train)\n",
        "\n",
        "  #Printing accuracy\n",
        "  y_pred = predictor.predict(test.drop(columns=[label]))\n",
        "  predictor.evaluate(test, silent=True)\n",
        "  acc[id]=predictor.evaluate(test, silent=True)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_fZQWSHgRkM",
        "outputId": "d83a0186-122d-46a0-c204-5bc6ebaf3f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loaded data from: Selfi/Valence/user_12.csv | Columns = 10 / 10 | Rows = 4374 -> 4374\n",
            "Loaded data from: Tap/Valence/user_12.csv | Columns = 10 / 10 | Rows = 732 -> 732\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144526/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144526/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    4374\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11924.92 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.73 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.22 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.11431184270690443, Train Rows: 3874, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.188\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.088\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.47\t = Validation score   (accuracy)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.482\t = Validation score   (accuracy)\n",
            "\t0.48s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.232\t = Validation score   (accuracy)\n",
            "\t2.93s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.228\t = Validation score   (accuracy)\n",
            "\t8.42s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.48\t = Validation score   (accuracy)\n",
            "\t1.62s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.22\t = Validation score   (accuracy)\n",
            "\t2.05s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.248\t = Validation score   (accuracy)\n",
            "\t1.27s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 4: early stopping\n",
            "\t0.52\t = Validation score   (accuracy)\n",
            "\t3.7s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.494\t = Validation score   (accuracy)\n",
            "\t0.55s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.508\t = Validation score   (accuracy)\n",
            "\t3.07s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.432\t = Validation score   (accuracy)\n",
            "\t1.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.544\t = Validation score   (accuracy)\n",
            "\t1.57s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 29.6s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144526/\")\n",
            "Loaded data from: Selfi/Valence/user_13.csv | Columns = 10 / 10 | Rows = 3478 -> 3478\n",
            "Loaded data from: Tap/Valence/user_13.csv | Columns = 10 / 10 | Rows = 642 -> 642\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144557/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144557/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    3478\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11918.24 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.58 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTrain Data (Processed) Memory Usage: 0.17 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1437607820586544, Train Rows: 2978, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.23\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.114\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.47\t = Validation score   (accuracy)\n",
            "\t0.61s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.472\t = Validation score   (accuracy)\n",
            "\t0.68s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.248\t = Validation score   (accuracy)\n",
            "\t4.05s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.258\t = Validation score   (accuracy)\n",
            "\t4.65s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.45\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.254\t = Validation score   (accuracy)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.252\t = Validation score   (accuracy)\n",
            "\t1.08s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.512\t = Validation score   (accuracy)\n",
            "\t3.33s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.486\t = Validation score   (accuracy)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.516\t = Validation score   (accuracy)\n",
            "\t3.61s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.396\t = Validation score   (accuracy)\n",
            "\t1.45s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.522\t = Validation score   (accuracy)\n",
            "\t1.68s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 25.33s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144557/\")\n",
            "Loaded data from: Selfi/Valence/user_14.csv | Columns = 10 / 10 | Rows = 4730 -> 4730\n",
            "Loaded data from: Tap/Valence/user_14.csv | Columns = 10 / 10 | Rows = 170 -> 170\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144622/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144622/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    4730\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11931.77 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.79 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.10570824524312897, Train Rows: 4230, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.21\t = Validation score   (accuracy)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.078\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.446\t = Validation score   (accuracy)\n",
            "\t0.69s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.486\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.206\t = Validation score   (accuracy)\n",
            "\t5.06s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.19\t = Validation score   (accuracy)\n",
            "\t4.95s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.516\t = Validation score   (accuracy)\n",
            "\t1.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.202\t = Validation score   (accuracy)\n",
            "\t1.43s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.202\t = Validation score   (accuracy)\n",
            "\t3.23s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 1: early stopping\n",
            "\t0.522\t = Validation score   (accuracy)\n",
            "\t5.68s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.514\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.522\t = Validation score   (accuracy)\n",
            "\t5.32s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.46\t = Validation score   (accuracy)\n",
            "\t0.95s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.536\t = Validation score   (accuracy)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 33.34s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144622/\")\n",
            "Loaded data from: Selfi/Valence/user_15.csv | Columns = 10 / 10 | Rows = 2352 -> 2352\n",
            "Loaded data from: Tap/Valence/user_15.csv | Columns = 10 / 10 | Rows = 784 -> 784\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144656/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144656/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    2352\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11918.43 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.39 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1881, Val Rows: 471\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2208\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1338\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4671\t = Validation score   (accuracy)\n",
            "\t0.36s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4671\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2442\t = Validation score   (accuracy)\n",
            "\t1.45s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2505\t = Validation score   (accuracy)\n",
            "\t2.04s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.5032\t = Validation score   (accuracy)\n",
            "\t1.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2484\t = Validation score   (accuracy)\n",
            "\t1.61s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2314\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 5: early stopping\n",
            "\t0.4862\t = Validation score   (accuracy)\n",
            "\t3.32s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4798\t = Validation score   (accuracy)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5074\t = Validation score   (accuracy)\n",
            "\t3.64s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3992\t = Validation score   (accuracy)\n",
            "\t0.89s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5138\t = Validation score   (accuracy)\n",
            "\t1.06s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 19.76s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144656/\")\n",
            "Loaded data from: Selfi/Valence/user_16.csv | Columns = 10 / 10 | Rows = 3906 -> 3906\n",
            "Loaded data from: Tap/Valence/user_16.csv | Columns = 10 / 10 | Rows = 1150 -> 1150\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144716/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144716/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    3906\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11923.35 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.65 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.12800819252432155, Train Rows: 3406, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.192\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.102\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.478\t = Validation score   (accuracy)\n",
            "\t0.42s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.466\t = Validation score   (accuracy)\n",
            "\t0.46s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.244\t = Validation score   (accuracy)\n",
            "\t2.58s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t3.86s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.488\t = Validation score   (accuracy)\n",
            "\t1.53s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t2.09s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t2.24s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 7: early stopping\n",
            "\t0.498\t = Validation score   (accuracy)\n",
            "\t5.75s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.494\t = Validation score   (accuracy)\n",
            "\t0.52s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.516\t = Validation score   (accuracy)\n",
            "\t3.23s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.412\t = Validation score   (accuracy)\n",
            "\t0.93s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.53\t = Validation score   (accuracy)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 26.78s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144716/\")\n",
            "Loaded data from: Selfi/Valence/user_17.csv | Columns = 10 / 10 | Rows = 1986 -> 1986\n",
            "Loaded data from: Tap/Valence/user_17.csv | Columns = 10 / 10 | Rows = 0 -> 0\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144743/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144743/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    1986\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11922.07 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.33 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1588, Val Rows: 398\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2638\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1482\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4849\t = Validation score   (accuracy)\n",
            "\t0.35s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4799\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3141\t = Validation score   (accuracy)\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.3266\t = Validation score   (accuracy)\n",
            "\t2.44s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4975\t = Validation score   (accuracy)\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2965\t = Validation score   (accuracy)\n",
            "\t1.36s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.299\t = Validation score   (accuracy)\n",
            "\t1.58s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 2: early stopping\n",
            "\t0.5151\t = Validation score   (accuracy)\n",
            "\t2.63s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4749\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5226\t = Validation score   (accuracy)\n",
            "\t2.77s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3995\t = Validation score   (accuracy)\n",
            "\t1.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5377\t = Validation score   (accuracy)\n",
            "\t1.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 18.25s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144743/\")\n",
            "Loaded data from: Selfi/Valence/user_18.csv | Columns = 10 / 10 | Rows = 662 -> 662\n",
            "Loaded data from: Tap/Valence/user_18.csv | Columns = 10 / 10 | Rows = 0 -> 0\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144801/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144801/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    662\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11922.22 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.11 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 529, Val Rows: 133\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.1955\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0752\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4511\t = Validation score   (accuracy)\n",
            "\t0.25s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.3158\t = Validation score   (accuracy)\n",
            "\t0.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.1654\t = Validation score   (accuracy)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.1654\t = Validation score   (accuracy)\n",
            "\t0.94s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.3308\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.1504\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.1729\t = Validation score   (accuracy)\n",
            "\t0.72s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5338\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.3985\t = Validation score   (accuracy)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.4962\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.2932\t = Validation score   (accuracy)\n",
            "\t0.59s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5338\t = Validation score   (accuracy)\n",
            "\t1.09s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 8.73s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144801/\")\n",
            "Loaded data from: Selfi/Valence/user_19.csv | Columns = 10 / 10 | Rows = 3184 -> 3184\n",
            "Loaded data from: Tap/Valence/user_19.csv | Columns = 10 / 10 | Rows = 239 -> 239\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144810/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144810/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    3184\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11913.29 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.53 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.16 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.157035175879397, Train Rows: 2683, Val Rows: 501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2156\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0918\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.477\t = Validation score   (accuracy)\n",
            "\t0.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4451\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2275\t = Validation score   (accuracy)\n",
            "\t3.74s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2415\t = Validation score   (accuracy)\n",
            "\t5.4s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.489\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2216\t = Validation score   (accuracy)\n",
            "\t1.12s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2295\t = Validation score   (accuracy)\n",
            "\t1.18s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 5: early stopping\n",
            "\t0.5269\t = Validation score   (accuracy)\n",
            "\t2.85s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4591\t = Validation score   (accuracy)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.489\t = Validation score   (accuracy)\n",
            "\t3.46s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3832\t = Validation score   (accuracy)\n",
            "\t1.46s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5269\t = Validation score   (accuracy)\n",
            "\t1.67s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 25.36s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144810/\")\n",
            "Loaded data from: Selfi/Valence/user_20.csv | Columns = 10 / 10 | Rows = 4644 -> 4644\n",
            "Loaded data from: Tap/Valence/user_20.csv | Columns = 10 / 10 | Rows = 208 -> 208\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144836/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144836/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    4644\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11914.6 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.77 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.23 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.18s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.10766580534022395, Train Rows: 4144, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.194\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.068\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.454\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.504\t = Validation score   (accuracy)\n",
            "\t0.79s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2\t = Validation score   (accuracy)\n",
            "\t5.97s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.212\t = Validation score   (accuracy)\n",
            "\t5.0s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.52\t = Validation score   (accuracy)\n",
            "\t1.06s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.206\t = Validation score   (accuracy)\n",
            "\t1.48s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.214\t = Validation score   (accuracy)\n",
            "\t1.51s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 1: early stopping\n",
            "\t0.546\t = Validation score   (accuracy)\n",
            "\t5.57s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.498\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.516\t = Validation score   (accuracy)\n",
            "\t6.75s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.43\t = Validation score   (accuracy)\n",
            "\t1.0s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.568\t = Validation score   (accuracy)\n",
            "\t1.11s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 34.05s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144836/\")\n",
            "Loaded data from: Selfi/Valence/user_23.csv | Columns = 10 / 10 | Rows = 2798 -> 2798\n",
            "Loaded data from: Tap/Valence/user_23.csv | Columns = 10 / 10 | Rows = 814 -> 814\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144910/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144910/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    2798\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11918.91 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.47 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.17869907076483202, Train Rows: 2298, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.218\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.098\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.496\t = Validation score   (accuracy)\n",
            "\t0.38s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.454\t = Validation score   (accuracy)\n",
            "\t0.45s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t1.77s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.232\t = Validation score   (accuracy)\n",
            "\t2.53s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.456\t = Validation score   (accuracy)\n",
            "\t0.9s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.216\t = Validation score   (accuracy)\n",
            "\t1.6s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.22\t = Validation score   (accuracy)\n",
            "\t1.8s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.512\t = Validation score   (accuracy)\n",
            "\t4.34s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.476\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.508\t = Validation score   (accuracy)\n",
            "\t5.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.406\t = Validation score   (accuracy)\n",
            "\t0.94s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.514\t = Validation score   (accuracy)\n",
            "\t1.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 23.29s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144910/\")\n",
            "Loaded data from: Selfi/Valence/user_25.csv | Columns = 10 / 10 | Rows = 3672 -> 3672\n",
            "Loaded data from: Tap/Valence/user_25.csv | Columns = 10 / 10 | Rows = 271 -> 271\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_144934/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_144934/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    3672\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11906.32 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.61 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.15s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.13616557734204793, Train Rows: 3172, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.206\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.094\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.46\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.458\t = Validation score   (accuracy)\n",
            "\t0.47s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t2.41s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.232\t = Validation score   (accuracy)\n",
            "\t4.61s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.486\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.236\t = Validation score   (accuracy)\n",
            "\t2.56s\t = Training   runtime\n",
            "\t0.19s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.25\t = Validation score   (accuracy)\n",
            "\t3.08s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 9: early stopping\n",
            "\t0.532\t = Validation score   (accuracy)\n",
            "\t4.67s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.482\t = Validation score   (accuracy)\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.514\t = Validation score   (accuracy)\n",
            "\t2.63s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.398\t = Validation score   (accuracy)\n",
            "\t0.98s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.538\t = Validation score   (accuracy)\n",
            "\t1.11s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 27.43s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_144934/\")\n",
            "Loaded data from: Selfi/Valence/user_26.csv | Columns = 10 / 10 | Rows = 1388 -> 1388\n",
            "Loaded data from: Tap/Valence/user_26.csv | Columns = 10 / 10 | Rows = 1600 -> 1600\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_145002/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_145002/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    1388\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11905.32 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.23 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.12s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1110, Val Rows: 278\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.223\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0971\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4712\t = Validation score   (accuracy)\n",
            "\t0.3s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.446\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2626\t = Validation score   (accuracy)\n",
            "\t1.21s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.277\t = Validation score   (accuracy)\n",
            "\t2.49s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4712\t = Validation score   (accuracy)\n",
            "\t1.32s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2662\t = Validation score   (accuracy)\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.12s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2626\t = Validation score   (accuracy)\n",
            "\t1.43s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t2.57s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4856\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.5468\t = Validation score   (accuracy)\n",
            "\t2.1s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3381\t = Validation score   (accuracy)\n",
            "\t0.93s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5468\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 16.92s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_145002/\")\n",
            "Loaded data from: Selfi/Valence/user_29.csv | Columns = 10 / 10 | Rows = 1642 -> 1642\n",
            "Loaded data from: Tap/Valence/user_29.csv | Columns = 10 / 10 | Rows = 600 -> 600\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_145019/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_145019/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    1642\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11917.05 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.08 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.14s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1313, Val Rows: 329\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2888\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1641\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4742\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.462\t = Validation score   (accuracy)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2918\t = Validation score   (accuracy)\n",
            "\t1.21s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2736\t = Validation score   (accuracy)\n",
            "\t1.57s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4742\t = Validation score   (accuracy)\n",
            "\t0.82s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2736\t = Validation score   (accuracy)\n",
            "\t0.91s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2644\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 1: early stopping\n",
            "\t0.5198\t = Validation score   (accuracy)\n",
            "\t2.08s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.5106\t = Validation score   (accuracy)\n",
            "\t0.62s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.538\t = Validation score   (accuracy)\n",
            "\t2.16s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.386\t = Validation score   (accuracy)\n",
            "\t1.48s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5471\t = Validation score   (accuracy)\n",
            "\t1.52s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 15.36s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_145019/\")\n",
            "Loaded data from: Selfi/Valence/user_32.csv | Columns = 10 / 10 | Rows = 2436 -> 2436\n",
            "Loaded data from: Tap/Valence/user_32.csv | Columns = 10 / 10 | Rows = 140 -> 140\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_145034/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_145034/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    2436\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11915.26 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.41 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1948, Val Rows: 488\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.2541\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1127\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4734\t = Validation score   (accuracy)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4713\t = Validation score   (accuracy)\n",
            "\t0.7s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2377\t = Validation score   (accuracy)\n",
            "\t2.94s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2336\t = Validation score   (accuracy)\n",
            "\t2.19s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4877\t = Validation score   (accuracy)\n",
            "\t0.87s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2111\t = Validation score   (accuracy)\n",
            "\t0.97s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2111\t = Validation score   (accuracy)\n",
            "\t0.96s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 6: early stopping\n",
            "\t0.5061\t = Validation score   (accuracy)\n",
            "\t2.31s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4877\t = Validation score   (accuracy)\n",
            "\t0.44s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.4898\t = Validation score   (accuracy)\n",
            "\t2.1s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3914\t = Validation score   (accuracy)\n",
            "\t1.49s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5102\t = Validation score   (accuracy)\n",
            "\t1.64s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 18.76s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_145034/\")\n",
            "Loaded data from: Selfi/Valence/user_33.csv | Columns = 10 / 10 | Rows = 248 -> 248\n",
            "Loaded data from: Tap/Valence/user_33.csv | Columns = 10 / 10 | Rows = 992 -> 992\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_145053/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_145053/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    248\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11915.82 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 198, Val Rows: 50\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.22\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.14\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.44\t = Validation score   (accuracy)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.3\t = Validation score   (accuracy)\n",
            "\t0.96s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.24\t = Validation score   (accuracy)\n",
            "\t1.03s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4\t = Validation score   (accuracy)\n",
            "\t1.03s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.22\t = Validation score   (accuracy)\n",
            "\t0.92s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.24\t = Validation score   (accuracy)\n",
            "\t0.9s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5\t = Validation score   (accuracy)\n",
            "\t2.11s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.38\t = Validation score   (accuracy)\n",
            "\t0.33s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.52\t = Validation score   (accuracy)\n",
            "\t0.64s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.36\t = Validation score   (accuracy)\n",
            "\t0.31s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.52\t = Validation score   (accuracy)\n",
            "\t0.76s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 10.57s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_145053/\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{12: {'accuracy': 0.5454961133973479, 'balanced_accuracy': 0.5467624846320474, 'mcc': 0.09889421030141175, 'roc_auc': 0.5762886080607525, 'f1': 0.6077348066298344, 'precision': 0.5314009661835749, 'recall': 0.7096774193548387}, 13: {'accuracy': 0.5181138585393904, 'balanced_accuracy': 0.5169305555555556, 'mcc': 0.0365156217799075, 'roc_auc': 0.5271269841269841, 'f1': 0.4048295454545454, 'precision': 0.5238970588235294, 'recall': 0.3298611111111111}, 14: {'accuracy': 0.5124735729386892, 'balanced_accuracy': 0.5131988388512696, 'mcc': 0.026495773752850237, 'roc_auc': 0.5274674768192308, 'f1': 0.5291955900367498, 'precision': 0.5038880248833593, 'recall': 0.5571797076526225}, 15: {'accuracy': 0.5255102040816326, 'balanced_accuracy': 0.5228227290082961, 'mcc': 0.05371452229959094, 'roc_auc': 0.5345725294178902, 'f1': 0.626005361930295, 'precision': 0.5200445434298441, 'recall': 0.7861952861952862}, 16: {'accuracy': 0.5304659498207885, 'balanced_accuracy': 0.5297483953517641, 'mcc': 0.06032528727380726, 'roc_auc': 0.5493743969459244, 'f1': 0.485698261357263, 'precision': 0.5312883435582823, 'recall': 0.44731404958677684}, 17: {'accuracy': 0.5448136958710977, 'balanced_accuracy': 0.5424818039451157, 'mcc': 0.09370920462328146, 'roc_auc': 0.5553022127376441, 'f1': 0.4190231362467866, 'precision': 0.5679442508710801, 'recall': 0.3319755600814664}, 18: {'accuracy': 0.5166163141993958, 'balanced_accuracy': 0.5179627601314348, 'mcc': 0.07921194203212793, 'roc_auc': 0.5079225994888645, 'f1': 0.6652719665271967, 'precision': 0.5079872204472844, 'recall': 0.9636363636363636}, 19: {'accuracy': 0.5282663316582915, 'balanced_accuracy': 0.5278437655378155, 'mcc': 0.055842837877408485, 'roc_auc': 0.5231226372655023, 'f1': 0.5478627332931968, 'precision': 0.5315420560747663, 'recall': 0.5652173913043478}, 20: {'accuracy': 0.5404823428079242, 'balanced_accuracy': 0.5389448653398565, 'mcc': 0.07884929818723638, 'roc_auc': 0.5504170278582625, 'f1': 0.49598488427019366, 'precision': 0.5362614913176711, 'recall': 0.46133567662565905}, 23: {'accuracy': 0.5260900643316655, 'balanced_accuracy': 0.5240037620887771, 'mcc': 0.049010440235511744, 'roc_auc': 0.5283996810402993, 'f1': 0.4666130329847144, 'precision': 0.5197132616487455, 'recall': 0.4233576642335766}, 25: {'accuracy': 0.5179738562091504, 'balanced_accuracy': 0.5165230115244535, 'mcc': 0.03459802199433017, 'roc_auc': 0.5251126515024749, 'f1': 0.4308681672025723, 'precision': 0.5185758513931888, 'recall': 0.36853685368536854}, 26: {'accuracy': 0.5489913544668588, 'balanced_accuracy': 0.5518426191366488, 'mcc': 0.10691494985481689, 'roc_auc': 0.5681000457019403, 'f1': 0.5940337224383916, 'precision': 0.5300925925925926, 'recall': 0.6755162241887905}, 29: {'accuracy': 0.559074299634592, 'balanced_accuracy': 0.5586856410378143, 'mcc': 0.12013130032526767, 'roc_auc': 0.5658307023998861, 'f1': 0.6021978021978022, 'precision': 0.5502008032128514, 'recall': 0.6650485436893204}, 32: {'accuracy': 0.5377668308702791, 'balanced_accuracy': 0.5390464835235979, 'mcc': 0.07862660921320984, 'roc_auc': 0.5484931699000841, 'f1': 0.5591229444009397, 'precision': 0.5242290748898678, 'recall': 0.5989932885906041}, 33: {'accuracy': 0.5645161290322581, 'balanced_accuracy': 0.5669023304529981, 'mcc': 0.13352524601290505, 'roc_auc': 0.5420267085624508, 'f1': 0.5573770491803279, 'precision': 0.5230769230769231, 'recall': 0.5964912280701754}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Arousal\n",
        "users=[12,13,14,15,16,17,18,19,20,23,25,26,29,32,33]\n",
        "acc={}\n",
        "for id in users:\n",
        "  dataset = TabularDataset('Selfi/Arousal/user_' + str(id)+'.csv')\n",
        "  print(\"------- id=\",id)\n",
        "  if(len(dataset)==0):\n",
        "    continue \n",
        "  dataset.drop('Sample id', inplace=True, axis=1) #removing the sample id column \n",
        "  train= dataset\n",
        "  dataset2=TabularDataset('Tap/Arousal/user_' + str(id)+'.csv')\n",
        "  temp, test=train_test_split(dataset, test_size=0.50)\n",
        "  label = 'Did the user report?'\n",
        "  train[label].describe()\n",
        "\n",
        "  predictor = TabularPredictor(label=label).fit(train)\n",
        "\n",
        "  #Printing accuracy\n",
        "  y_pred = predictor.predict(test.drop(columns=[label]))\n",
        "  predictor.evaluate(test, silent=True)\n",
        "  acc[id]=predictor.evaluate(test, silent=True)\n",
        "\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "sDXmbwP3nKtM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf8604f6-f5b5-4ed5-b438-ae8fe4652b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loaded data from: Selfi/Arousal/user_12.csv | Columns = 10 / 10 | Rows = 4402 -> 4402\n",
            "Loaded data from: Tap/Arousal/user_12.csv | Columns = 10 / 10 | Rows = 766 -> 766\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_171658/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_171658/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    4402\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11657.76 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.73 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.22 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.11358473421172194, Train Rows: 3902, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.196\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.104\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.456\t = Validation score   (accuracy)\n",
            "\t0.5s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.49\t = Validation score   (accuracy)\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.234\t = Validation score   (accuracy)\n",
            "\t2.96s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.236\t = Validation score   (accuracy)\n",
            "\t6.4s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.488\t = Validation score   (accuracy)\n",
            "\t1.78s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t2.4s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.232\t = Validation score   (accuracy)\n",
            "\t2.46s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 4: early stopping\n",
            "\t0.534\t = Validation score   (accuracy)\n",
            "\t3.84s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.474\t = Validation score   (accuracy)\n",
            "\t0.53s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.494\t = Validation score   (accuracy)\n",
            "\t9.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.396\t = Validation score   (accuracy)\n",
            "\t1.5s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.544\t = Validation score   (accuracy)\n",
            "\t1.69s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 36.16s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_171658/\")\n",
            "Loaded data from: Selfi/Arousal/user_13.csv | Columns = 10 / 10 | Rows = 3528 -> 3528\n",
            "Loaded data from: Tap/Arousal/user_13.csv | Columns = 10 / 10 | Rows = 624 -> 624\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_171735/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_171735/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    3528\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11657.63 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.59 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.17s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1417233560090703, Train Rows: 3028, Val Rows: 500\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.256\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.03s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.112\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.462\t = Validation score   (accuracy)\n",
            "\t0.67s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.43\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.234\t = Validation score   (accuracy)\n",
            "\t4.14s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.238\t = Validation score   (accuracy)\n",
            "\t3.4s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.478\t = Validation score   (accuracy)\n",
            "\t0.93s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.228\t = Validation score   (accuracy)\n",
            "\t1.14s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.224\t = Validation score   (accuracy)\n",
            "\t1.22s\t = Training   runtime\n",
            "\t0.13s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "\t0.526\t = Validation score   (accuracy)\n",
            "\t3.99s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.466\t = Validation score   (accuracy)\n",
            "\t0.83s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.486\t = Validation score   (accuracy)\n",
            "\t4.24s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.41\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.528\t = Validation score   (accuracy)\n",
            "\t1.73s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 26.22s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_171735/\")\n",
            "Loaded data from: Selfi/Arousal/user_14.csv | Columns = 10 / 10 | Rows = 4820 -> 4820\n",
            "Loaded data from: Tap/Arousal/user_14.csv | Columns = 10 / 10 | Rows = 976 -> 976\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_171802/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_171802/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    4820\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11658.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.8 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.1037344398340249, Train Rows: 4319, Val Rows: 501\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.1856\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.0918\t = Validation score   (accuracy)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4711\t = Validation score   (accuracy)\n",
            "\t0.74s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.479\t = Validation score   (accuracy)\n",
            "\t0.77s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2076\t = Validation score   (accuracy)\n",
            "\t3.4s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2196\t = Validation score   (accuracy)\n",
            "\t4.93s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.493\t = Validation score   (accuracy)\n",
            "\t1.04s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2076\t = Validation score   (accuracy)\n",
            "\t2.1s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2036\t = Validation score   (accuracy)\n",
            "\t2.64s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.519\t = Validation score   (accuracy)\n",
            "\t6.16s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.4691\t = Validation score   (accuracy)\n",
            "\t0.92s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.507\t = Validation score   (accuracy)\n",
            "\t3.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.481\t = Validation score   (accuracy)\n",
            "\t1.01s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5369\t = Validation score   (accuracy)\n",
            "\t1.13s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 31.0s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_171802/\")\n",
            "Loaded data from: Selfi/Arousal/user_15.csv | Columns = 10 / 10 | Rows = 2404 -> 2404\n",
            "Loaded data from: Tap/Arousal/user_15.csv | Columns = 10 / 10 | Rows = 798 -> 798\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_171833/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_171833/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    2404\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11664.41 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.4 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.12 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 1923, Val Rows: 481\n",
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\t0.2432\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.131\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.4283\t = Validation score   (accuracy)\n",
            "\t0.4s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.4283\t = Validation score   (accuracy)\n",
            "\t0.49s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n",
            "\t0.2536\t = Validation score   (accuracy)\n",
            "\t1.48s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ...\n",
            "\t0.2557\t = Validation score   (accuracy)\n",
            "\t2.8s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: CatBoost ...\n",
            "\t0.4615\t = Validation score   (accuracy)\n",
            "\t1.39s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ...\n",
            "\t0.2287\t = Validation score   (accuracy)\n",
            "\t1.56s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ...\n",
            "\t0.2432\t = Validation score   (accuracy)\n",
            "\t1.55s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ...\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.5156\t = Validation score   (accuracy)\n",
            "\t2.67s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ...\n",
            "\t0.42\t = Validation score   (accuracy)\n",
            "\t0.73s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ...\n",
            "\t0.4906\t = Validation score   (accuracy)\n",
            "\t2.57s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ...\n",
            "\t0.3742\t = Validation score   (accuracy)\n",
            "\t0.98s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ...\n",
            "\t0.5177\t = Validation score   (accuracy)\n",
            "\t1.08s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 19.07s ... Best model: \"WeightedEnsemble_L2\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20230430_171833/\")\n",
            "Loaded data from: Selfi/Arousal/user_16.csv | Columns = 10 / 10 | Rows = 3946 -> 3946\n",
            "Loaded data from: Tap/Arousal/user_16.csv | Columns = 10 / 10 | Rows = 1218 -> 1218\n",
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20230430_171852/\"\n",
            "Beginning AutoGluon training ...\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20230430_171852/\"\n",
            "AutoGluon Version:  0.7.0\n",
            "Python Version:     3.10.11\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Sat Dec 10 16:00:40 UTC 2022\n",
            "Train Data Rows:    3946\n",
            "Train Data Columns: 8\n",
            "Label Column: Did the user report?\n",
            "Preprocessing data ...\n",
            "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
            "\t2 unique label values:  ['No', 'Yes']\n",
            "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
            "Selected class <--> label mapping:  class 1 = Yes, class 0 = No\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Yes) vs negative (No) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11660.5 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.66 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('object', []) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', [])     : 6 | ['Duration from office start', 'Duration from office end', 'Duration from office break start', 'Duration from office break end', 'Elapsed time from last reported 0', ...]\n",
            "\t\t('int', ['bool']) : 2 | ['Within office hour', 'Within office break hour']\n",
            "\t0.1s = Fit runtime\n",
            "\t8 features in original data used to generate 8 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.2 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.13s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.12671059300557527, Train Rows: 3446, Val Rows: 500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------- id= 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fitting 13 L1 models ...\n",
            "Fitting model: KNeighborsUnif ...\n",
            "\t0.228\t = Validation score   (accuracy)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ...\n",
            "\t0.1\t = Validation score   (accuracy)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ...\n",
            "\t0.464\t = Validation score   (accuracy)\n",
            "\t0.47s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ...\n",
            "\t0.464\t = Validation score   (accuracy)\n",
            "\t0.51s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-98e84590e0c3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m#Printing accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fit_weighted_ensemble'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Save predictor to disk to enable prediction and training after interrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,\n\u001b[0m\u001b[1;32m    867\u001b[0m                           \u001b[0mholdout_frac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholdout_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_bag_sets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                           \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/abstract_learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learner is already fit.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/learner/default_learner.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         trainer.fit(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/trainer/auto_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                      '\\tpredictor.fit(..., tuning_data=tuning_data, use_bag_holdout=True)')\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         self._train_multi_and_ensemble(X=X,\n\u001b[0m\u001b[1;32m     99\u001b[0m                                        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                                        \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_and_ensemble\u001b[0;34m(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001b[0m\n\u001b[1;32m   2049\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_rows_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_cols_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2051\u001b[0;31m         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,\n\u001b[0m\u001b[1;32m   2052\u001b[0m                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mtrain_multi_levels\u001b[0;34m(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_core\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs_level\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time_limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit_aux\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             base_model_names, aux_models = self.stack_new_level(\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_unlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_unlabeled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_model_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0maux_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name_suffix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models,\n\u001b[0m\u001b[1;32m    430\u001b[0m                                                 level=level, infer_limit=infer_limit, infer_limit_batch_size=infer_limit_batch_size, base_model_names=base_model_names, **core_kwargs)\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36mstack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m         return self._train_multi(X=X_init, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled,\n\u001b[0m\u001b[1;32m    521\u001b[0m                                  models=models, level=level, stack_name=stack_name, compute_score=compute_score, fit_kwargs=fit_kwargs, **kwargs)\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m             \u001b[0mtime_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m             model_names_trained = self._train_multi_initial(X=X, y=y, models=models, k_fold=k_fold, n_repeats=n_repeats_initial, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   2022\u001b[0m                                                             feature_prune_kwargs=feature_prune_kwargs, time_limit=time_limit, **kwargs)\n\u001b[1;32m   2023\u001b[0m             \u001b[0mn_repeat_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_repeats_initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbagged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1912\u001b[0m             \u001b[0mtime_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpo_time_ratio\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhpo_enabled\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1913\u001b[0;31m             models = self._train_multi_fold(models=models, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n\u001b[0m\u001b[1;32m   1914\u001b[0m                                             time_limit=time_limit, time_split=time_split, time_ratio=time_ratio, **fit_args)\n\u001b[1;32m   1915\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   1990\u001b[0m                     \u001b[0mtime_start_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m                     \u001b[0mtime_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime_start_model\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1992\u001b[0;31m             \u001b[0mmodel_name_trained_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameter_tune_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameter_tune_kwargs_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                 \u001b[0mbagged_model_fit_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_bagged_model_fit_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_fold_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeat_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeat_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagged_model_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1810\u001b[0;31m             model_names_trained = self._train_and_save(\n\u001b[0m\u001b[1;32m   1811\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_w_pseudo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1502\u001b[0;31m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mfit_end_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/trainer/abstract_trainer.py\u001b[0m in \u001b[0;36m_train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \"\"\"\n\u001b[0;32m-> 1447\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_resources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_resources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_fit_resources\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_fit_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/rf/rf_model.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, num_cpus, time_limit, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_estimators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimator_increments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_train_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# avoid it being too small and being truncated to 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}