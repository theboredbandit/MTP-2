{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-trycaw7-0WG"
      },
      "source": [
        "Run the code following two steps:\n",
        "\n",
        "\n",
        "1.   List the features returned by the image analysis tool (Rekognition/Vision/Azure) by excuting one of the three code blocks\n",
        "2. Run the final code block to evaluate the framework.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpFrV9yGIfc-",
        "outputId": "f9e059b8-f980-494f-ec7c-9ea744ee0670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  Data.zip\n",
            "   creating: Data/FacialData/\n",
            "   creating: Data/FacialData/Amazon/\n",
            "  inflating: Data/FacialData/Amazon/user_31.csv  \n",
            "   creating: Data/FacialData/Google/\n",
            "  inflating: Data/FacialData/Google/user_31.csv  \n",
            "   creating: Data/FacialData/Microsoft/\n",
            "  inflating: Data/FacialData/Microsoft/user_31.csv  \n",
            "   creating: Data/Self_reports/\n",
            "   creating: Data/Self_reports/Arousal/\n",
            "  inflating: Data/Self_reports/Arousal/user_31.csv  \n",
            "   creating: Data/Self_reports/Valence/\n",
            "  inflating: Data/Self_reports/Valence/user_31.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip Data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPLljU2fJ9nH",
        "outputId": "727b342b-8254-491c-d492-a526b71503a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyDML\n",
            "  Downloading pyDML-0.1.0.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyDML) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pyDML) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyDML) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyDML) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from pyDML) (0.29.34)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyDML) (1.10.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from pyDML) (0.12.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (1.4.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyDML) (1.0.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pyDML) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyDML) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyDML) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pyDML) (1.16.0)\n",
            "Building wheels for collected packages: pyDML\n",
            "  Building wheel for pyDML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDML: filename=pyDML-0.1.0-cp310-cp310-linux_x86_64.whl size=5883453 sha256=2b8c1c8f94d1287127bb8341135137c3339d065804d70cf91e09aadd3836d331\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/e3/c4/178953a1ef489ed48dcd682135ce3b39b4c6e8b13db6739216\n",
            "Successfully built pyDML\n",
            "Installing collected packages: pyDML\n",
            "Successfully installed pyDML-0.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyDML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YCBgQ5fqbSc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import *\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.utils import np_utils\n",
        "from keras import optimizers\n",
        "import keras.backend as K\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import fnmatch\n",
        "import datetime\n",
        "import shutil\n",
        "from statistics import mean\n",
        "from sklearn.feature_selection import f_classif\n",
        "from itertools import combinations\n",
        "import math\n",
        "from numpy import percentile\n",
        "from dml import kda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCNqSQe25hS2"
      },
      "source": [
        "Necessary functions to compute self-report features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4jcEzKhm5b4"
      },
      "outputs": [],
      "source": [
        "def find_transition_matrix(values):\n",
        "\tsrc_labels=[0,1]\n",
        "\ttgt_labels=[0,1]\n",
        "\t\n",
        "\ttransition_vector=[]\n",
        "\t\n",
        "\tfor em_src in src_labels:\n",
        "\t\tsrc=values[values[:,0]==em_src,:]\n",
        "\t\tif src.shape[0] != 0:\n",
        "\t\t\tfor em_tgt in tgt_labels:\n",
        "\t\t\t\ttgt=src[src[:,1]==em_tgt,:]\n",
        "\t\t\t\ttrans_prob=tgt.shape[0]/float(src.shape[0])\t\t\t\n",
        "\t\t\t\ttransition_vector.append(trans_prob)\n",
        "\t\telse:\n",
        "\t\t\ttransition_vector.extend([0,0])\n",
        "\treturn transition_vector\n",
        "\n",
        "def find_average_sequence_length(values):\n",
        "\tseq_length_vector=[]\n",
        "\n",
        "\tseq_lengths_l=np.empty((0))\n",
        "\tseq_lengths_h=np.empty((0))\n",
        "\n",
        "\n",
        "\tcount=1\n",
        "\tfor i in range(1,values.shape[0]):\n",
        "\t\tif values[i,1]==0 and values[i,1]==values[i-1,1]:\t\t\t\t\n",
        "\t\t\t\tcount=count+1\n",
        "\t\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tif values[i-1,1]==0:\n",
        "\t\t\t\tseq_lengths_l=np.append(seq_lengths_l,count)\n",
        "\t\t\t\tcount=1\n",
        "\tif count>1 or seq_lengths_l.shape[0]==0:\n",
        "\t\tseq_lengths_l=np.append(seq_lengths_l,count)\t\n",
        "\n",
        "\tcount=1\n",
        "\tfor i in range(1,values.shape[0]):\n",
        "\t\tif values[i,1]==values[i-1,1] and values[i,1]==1:\n",
        "\t\t\tcount=count+1\n",
        "\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tif values[i-1,1]==1:\t\t\t\n",
        "\t\t\t\tseq_lengths_h=np.append(seq_lengths_h,count)\n",
        "\t\t\t\tcount=1\n",
        "\tif count>1 or seq_lengths_h.shape[0]==0:\n",
        "\t\tseq_lengths_h=np.append(seq_lengths_h,count)\n",
        "\n",
        "\t\t\n",
        "\n",
        "\tseq_length_vector.append(int(round(np.percentile(seq_lengths_l,75))))\n",
        "\tseq_length_vector.append(int(round(np.percentile(seq_lengths_h,75))))\n",
        "\t\n",
        "\n",
        "\t#print('seq vector:',np.array(seq_length_vector))\n",
        "\treturn np.array(seq_length_vector)\n",
        "\n",
        "def find_PRE(transition_vector,previous_label):\n",
        "\tif previous_label==0:\n",
        "\t\tlabel_vector=np.array([1,0])\n",
        "\telif previous_label==1:\n",
        "\t\tlabel_vector=np.array([0,1])\n",
        "\n",
        "\t\n",
        "\ttransition_matrix=np.empty((0,2))\n",
        "\ttransition_matrix=np.append(transition_matrix,np.array([transition_vector[0:2]]),axis=0)\n",
        "\ttransition_matrix=np.append(transition_matrix,np.array([transition_vector[2:4]]),axis=0)\n",
        "\n",
        "\n",
        "\tpredicted_val=np.matmul(label_vector,transition_matrix)\n",
        "\tidx=np.argmax(predicted_val)\n",
        "\n",
        "\tpredicted_val_sorted=np.sort(predicted_val)\n",
        "\n",
        "\tr=np.where(predicted_val==predicted_val_sorted[0])\n",
        "\tsec_idx=r[0][0]\n",
        "\n",
        "\t\n",
        "\t\n",
        "\tif idx==0:\n",
        "\t\tpre='low'\n",
        "\telif idx==1:\n",
        "\t\tpre='high'\n",
        "\n",
        "\n",
        "\tif sec_idx==0:\n",
        "\t\tpre_2='low'\n",
        "\telif sec_idx==1:\n",
        "\t\tpre_2='high'\n",
        "\t\n",
        "\n",
        "\ttotal_wt=np.sum(predicted_val)\n",
        "\tif total_wt==0:\n",
        "\t\tpredicted_val_norm=np.array([0,0])\n",
        "\telse:\n",
        "\t\tpredicted_val_norm=np.divide(predicted_val,total_wt)\n",
        "\n",
        "\treturn pre,pre_2,predicted_val_norm\n",
        "\n",
        "def find_val(label):\n",
        "   if label=='low':\n",
        "     val=0\n",
        "   elif label=='high':\n",
        "     val=1\n",
        "   return val  \n",
        "def find_label(val):\n",
        "\tif val==0:\n",
        "\t\tlabel='low'\n",
        "\telif val==1:\n",
        "\t\tlabel='high'\n",
        "\n",
        "\treturn label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEEAyrQk5aCl"
      },
      "source": [
        "Return facial features value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBIR-z3Bn9Ua"
      },
      "outputs": [],
      "source": [
        "def facial_feature(photo,common):\n",
        "  user_no=photo.split('/')[0]\n",
        "  # mention facial feature file\n",
        "  # for Amazon\n",
        "  user_file='Data/FacialData/Amazon/'+user_no+'.csv'\n",
        "  # for vision\n",
        "  #user_file='Data/FacialData/Google/'+user_no+'.csv'\n",
        "  # for Azure\n",
        "  # user_file='Data/FacialData/Microsoft/'+user_no+'.csv'\n",
        "  user_data=pd.read_csv(user_file)\n",
        "  df=user_data[user_data['FileName']==photo]\n",
        "  df=df[common]\n",
        "  #print(df)\n",
        "  feature_list=[]\n",
        "\n",
        "  df=df.to_numpy()\n",
        "  #print(df)\n",
        "  for k in range(df.shape[1]):\n",
        "    feature_list.append(df[0,k])\n",
        "  #print(feature_list)\n",
        "  return feature_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p5Bk-cZ5TuX"
      },
      "source": [
        "Remove duplicate data samples if any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Suil70EoCn2"
      },
      "outputs": [],
      "source": [
        "def data_stat(train_data):\n",
        "  np.set_printoptions(suppress=True)\n",
        "  uniquerows=np.unique(train_data,axis=0)\n",
        "  print(\"number of unique rows=\",uniquerows.shape)\n",
        "  return uniquerows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6yImOwR5PDF"
      },
      "source": [
        "Build the model and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBInTVV5oI-n"
      },
      "outputs": [],
      "source": [
        "def Random_Forest_model(train_data,test_data):\n",
        "\n",
        "  \n",
        "  print(\"train size in model function=\",train_data.shape[0],\"test size in model function=\",test_data.shape[0])\n",
        "  train_data=data_stat(train_data)\n",
        "  print(\"train size after removing duplicates=\",train_data.shape[0],\"test size after removing duplicates=\",test_data.shape[0])\n",
        "  \n",
        "  X_train=train_data[:,1:train_data.shape[1]]\n",
        "  Y_train=train_data[:,0]\n",
        "  X_test=test_data[:,1:test_data.shape[1]]\n",
        "  Y_test=test_data[:,0]\n",
        "  \n",
        "  \n",
        "\n",
        "  # define model\n",
        "  model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "  \n",
        "  s=model.fit(X_train,Y_train)\n",
        "\n",
        "  Y_pred=s.predict(X_test)\n",
        "  Y_predTrain=s.predict(X_train)\n",
        "  #importance = s.feature_importances_\n",
        "  #print(\"Y_train=\",Y_train)\n",
        "  \n",
        "  print(\"Y_test=\",Y_test)\n",
        "  print(\"Y_pred=\",Y_pred)\n",
        "  \n",
        "  \n",
        "  # f1 score\n",
        "  print(\"Train accuracy=\",f1_score(Y_train,Y_predTrain,average=\"macro\"))\n",
        "  train_score=f1_score(Y_train,Y_predTrain,average=\"macro\")\n",
        "  print(\"Test f1=\",f1_score(Y_test,Y_pred,average=\"macro\"))\n",
        "  test_score=f1_score(Y_test,Y_pred,average=\"macro\")\n",
        "  print(\"Test accuracy=\",accuracy_score(Y_test,Y_pred)) \n",
        "  accu_score=accuracy_score(Y_test,Y_pred)\n",
        "  print(classification_report(Y_test, Y_pred))\n",
        "  \n",
        "\n",
        "  return train_score,test_score,Y_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i9VkNB65Cl3"
      },
      "source": [
        "Create train and test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-a7NQpGoRk4"
      },
      "outputs": [],
      "source": [
        "def feature_file_creation(train_data,test_data,common):\n",
        "  # column_list need to add as argument when using correlation\n",
        "  feature_no=len(common)\n",
        "  accu_score=0\n",
        "  et_norm=np.empty((0))\n",
        "  et_from_last_label=np.array([0,0])\n",
        "  train_feature=np.empty((0,feature_no+4))\n",
        "  test_feature=np.empty((0,feature_no+4))\n",
        "  transition_matrix=find_transition_matrix(train_data)\n",
        "  \n",
        "  continuous_seq_len=1\n",
        "  \n",
        "  for i in range(0,train_data.shape[0]):\n",
        "  \n",
        "    pre,pre_2,label_wt=find_PRE(transition_matrix,train_data[i,0])\n",
        "    # compute elapsed time\n",
        "    if train_data[i,0]==0:\n",
        "          et_from_last_label[0]=train_data[i,4]\n",
        "          et_from_last_label[1]=et_from_last_label[1]+train_data[i,4]\n",
        "    elif train_data[i,0]==1: \n",
        "          et_from_last_label[1]=train_data[i,4] \n",
        "          et_from_last_label[0]=et_from_last_label[0]+train_data[i,4]\n",
        "        \n",
        "    max_et=np.amax(et_from_last_label)\n",
        "    \n",
        "    if(max_et==0):\n",
        "           continue\n",
        "    et_norm=np.divide(et_from_last_label,float(max_et))\n",
        "    # influence calculation\n",
        "    for j in range(0,2):\n",
        "          et_norm[j]=1-et_norm[j]\n",
        "          label_wt[j]=label_wt[j]*et_norm[j]\n",
        "    #print(\"influence:\",label_wt)\n",
        "\n",
        "    # sequence length calculation\n",
        "    if(i==0):\n",
        "       continuous_seq_len=1\n",
        "    else:\n",
        "\n",
        "      if train_data[i,0]==train_data[i,1]:\n",
        "          continuous_seq_len=continuous_seq_len+1\n",
        "      else:\n",
        "          continuous_seq_len=1\n",
        "\n",
        "    img_features=facial_feature(train_data[i,3],common)  \n",
        "    self_report=train_data[i,1]\n",
        "    train_instance_lst=[]\n",
        "    train_instance_lst.append(self_report)\n",
        "    train_instance_lst.append(label_wt[0])\n",
        "    train_instance_lst.append(label_wt[1])\n",
        "    train_instance_lst.append(continuous_seq_len)\n",
        "    train_instance_lst.extend(img_features)\n",
        "    \n",
        "    \n",
        "    train_instance=np.array(train_instance_lst).reshape(1,len(train_instance_lst))\n",
        "    \n",
        "    # training data\n",
        "    train_feature=np.append(train_feature,train_instance,axis=0)\n",
        "    \n",
        "  \n",
        "  # for test feature\n",
        "  \n",
        "  for p in range(0,test_data.shape[0]):\n",
        "    old_label=test_data[p,0]\n",
        "    pre,pre_2,label_wt=find_PRE(transition_matrix,old_label) \n",
        "    if old_label==0:\n",
        "          et_from_last_label[0]=test_data[p,4]\n",
        "          et_from_last_label[1]=et_from_last_label[1]+test_data[p,4]\n",
        "    elif old_label==1:\n",
        "          et_from_last_label[1]=test_data[p,4]\n",
        "          et_from_last_label[0]=et_from_last_label[0]+test_data[p,4]\n",
        "        \n",
        "    max_et=np.amax(et_from_last_label)\n",
        "    \n",
        "    if(max_et==0):\n",
        "\n",
        "          continue\n",
        "    et_norm=np.divide(et_from_last_label,float(max_et))\n",
        "    for j in range(0,2):\n",
        "          et_norm[j]=1-et_norm[j]\n",
        "          label_wt[j]=label_wt[j]*et_norm[j]\n",
        "\n",
        "    # sequence length calculation      \n",
        "    \n",
        "    if(test_data[p,0]==find_val(pre)):\n",
        "             continuous_seq_len+=1\n",
        "    else:    \n",
        "          continuous_seq_len=1\n",
        "    \n",
        "\n",
        "    img_features=facial_feature(test_data[p,3],common)      \n",
        "    self_report=test_data[p,1] \n",
        "    test_instance_lst=[]\n",
        "    # typing feature considered\n",
        "    test_instance_lst.append(self_report)\n",
        "    test_instance_lst.append(label_wt[0])\n",
        "    test_instance_lst.append(label_wt[1])\n",
        "    test_instance_lst.append(continuous_seq_len)\n",
        "    test_instance_lst.extend(img_features)\n",
        "    \n",
        "    test_instance=np.array(test_instance_lst).reshape(1,len(test_instance_lst))\n",
        "\n",
        "    test_feature=np.append(test_feature,test_instance,axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        " \n",
        "  return train_feature,test_feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcKEYCuv3ta_"
      },
      "source": [
        "Excute the below code block to list the features obtain from Amazon Rekognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqT9pmWfRkXm",
        "outputId": "bcadd7c5-23c9-4af5-aac5-ef5059879f2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(510, 65)\n",
            "['eyeLeftX', 'eyeLeftY', 'eyeRightX', 'eyeRightY', 'mouthLeftX', 'mouthLeftY', 'mouthRightX', 'mouthRightY', 'noseX', 'noseY', 'leftEyeBrowLeftX', 'leftEyeBrowLeftY', 'leftEyeBrowRightX', 'leftEyeBrowRightY', 'leftEyeBrowUpX', 'leftEyeBrowUpY', 'rightEyeBrowLeftX', 'rightEyeBrowLeftY', 'rightEyeBrowRightX', 'rightEyeBrowRightY', 'rightEyeBrowupX', 'rightEyeBrowupY', 'leftEyeLeftX', 'leftEyeLeftY', 'leftEyeRightX', 'leftEyeRightY', 'leftEyeUpX', 'leftEyeUpY', 'leftEyeDownX', 'leftEyeDownY', 'rightEyeLeftX', 'rightEyeLeftY', 'rightEyeRightX', 'rightEyeRightY', 'rightEyeUpX', 'rightEyeUpY', 'rightEyeDownX', 'rightEyeDownY', 'noseLeftX', 'noseLeftY', 'noseRightX', 'noseRightY', 'mouthUpX', 'mouthUpY', 'mouthDownX', 'mouthDownY', 'leftPupilX', 'leftPupilY', 'rightPupilX', 'rightPupilY', 'upperJawlineLeftX', 'upperJawlineLeftY', 'midJawlineLeftX', 'midJawlineLeftY', 'chinBottomX', 'chinBottomY', 'midJawlineRightX', 'midJawlineRightY', 'upperJawlineRightX', 'upperJawlineRightY', 'PoseRoll', 'PoseYaw', 'PosePitch', 'QualityBrightness', 'QualitySharpness']\n"
          ]
        }
      ],
      "source": [
        "# driver code\n",
        "user_no=15\n",
        "common=[]\n",
        "user_name='user_'+str(format(user_no,'02'))\n",
        "\n",
        "dirname='Data/FacialData/Amazon/'+user_name+'.csv'\n",
        "\n",
        "array=pd.read_csv(dirname)\n",
        "array=array.drop_duplicates(keep='last')\n",
        "array=array.drop(['FileName',\"TapEmotion\",'NewTarget'],axis=1)\n",
        "array=array.drop(['SmileValue_ False','SmileValue_ True','EyeglassesValue_ False','SunglassesValue_ False','SunglassesValue_ True',\"GenderValue_ 'Female'\",\"GenderValue_ 'Male'\",\"BeardValue_ False\",\n",
        "                            \"BeardValue_ True\",\"MustacheValue_ False\",\"EyesOpenValue_ False\",\"EyesOpenValue_ True\",\"MouthOpenValue_ False\",\"MouthOpenValue_ True\",\"MustacheValue_ True\",'EyeglassesValue_ True'],axis=1,errors='ignore')  \n",
        "array=array.drop(['Confidence','BoundingBoxWidth','BoundingBoxHeight','BoundingBoxLeft','BoundingBoxTop','AgeRangeLow','AgeRangeHigh','SmileConfidence', 'EyesOpenConfidence', 'MouthOpenConfidence','EyeglassesConfidence','SunglassesConfidence','GenderConfidence','BeardConfidence','MustacheConfidence','Date'], axis=1,errors='ignore')                          \n",
        "column_list=list(array.columns)\n",
        "print(array.shape)\n",
        "common=column_list\n",
        "print(common)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbaDCzBd4mdf"
      },
      "source": [
        "Excute the code to list the features obtain from Google Vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln8qJPcFOuBE"
      },
      "outputs": [],
      "source": [
        "# # for vision data processing\n",
        "# # driver code\n",
        "# user_no=31\n",
        "# common=[]\n",
        "# user_name='user_'+str(format(user_no,'02'))\n",
        "# dirname='Data/FacialData/Google/'+user_name+'.csv'\n",
        "\n",
        "# array=pd.read_csv(dirname)\n",
        "# array=array.drop_duplicates(keep='last')\n",
        "# array=array.drop(['FileName'],axis=1)\n",
        "\n",
        "# array=array.drop(['bounding_poly1x', 'bounding_poly1y', 'bounding_poly2x', 'bounding_poly2y', 'bounding_poly3x', 'bounding_poly3y', 'bounding_poly4x', 'bounding_poly4y', 'fdbounding_poly1x', 'fdbounding_poly1y', 'fdbounding_poly2x', 'fdbounding_poly2y', 'fdbounding_poly3x', 'fdbounding_poly3y', 'fdbounding_poly4x', 'fdbounding_poly4y','detection_confidence','landmarking_confidence','joy_likelihood','sorrow_likelihood','anger_likelihood','surprise_likelihood','emotion','target','Date'],axis=1,errors='ignore')  \n",
        "             \n",
        "# column_list=list(array.columns)\n",
        "# #print(column_list)\n",
        "# print(array.shape)\n",
        "# common=column_list\n",
        "# print(common)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuWxr4b443xU"
      },
      "source": [
        "Excute the code to list features obtain from Microsoft Azure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q45rzQoEjlrc",
        "outputId": "e765e18a-265d-437c-cdf4-8e60c47542dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(719, 40)\n",
            "['pupil_leftX', 'pupil_leftY', 'pupil_rightX', 'pupil_rightY', 'nose_tipX', 'nose_tipY', 'mouth_leftX', 'mouth_leftY', 'mouth_rightX', 'mouth_rightY', 'eyebrow_left_outerX', 'eyebrow_left_outerY', 'eyebrow_left_innerX', 'eyebrow_left_innerY', 'eye_left_outerX', 'eye_left_outerY', 'eye_left_topX', 'eye_left_topY', 'eye_left_bottomX', 'eye_left_bottomY', 'eye_left_innerX', 'eye_left_innerY', 'eyebrow_right_innerX', 'eyebrow_right_innerY', 'eyebrow_right_outerX', 'eyebrow_right_outerY', 'eye_right_innerX', 'eye_right_innerY', 'eye_right_topX', 'eye_right_topY', 'nose_right_alar_topX', 'nose_right_alar_topY', 'nose_left_alar_out_tipX', 'nose_left_alar_out_tipY', 'nose_right_alar_out_tipX', 'nose_right_alar_out_tipY', 'upper_lip_topX', 'upper_lip_topY', 'upper_lip_bottomX', 'upper_lip_bottomY']\n"
          ]
        }
      ],
      "source": [
        "# # for Azure Data Processing\n",
        "# user_no=12\n",
        "# common=[]\n",
        "# user_name='user_'+str(format(user_no,'02'))\n",
        "# dirname='Data/FacialData/Microsoft/'+user_name+'.csv'\n",
        "# array=pd.read_csv(dirname)\n",
        "# array=array.drop_duplicates(keep='last')\n",
        "# array=array.drop(['FileName'],axis=1)\n",
        "# column_list=list(array.columns)\n",
        "# print(array.shape)\n",
        "# common=column_list\n",
        "# print(common)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQcwqi4HBP3e",
        "outputId": "dfd3b53e-4ea7-4b9e-a817-69fc982009b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size= 649\n",
            "fold no= 1\n",
            "train data index= 0 --> 486 test data index= 487 ---> 649\n",
            "train_data size= 487 test data size= 162\n",
            "no. of high samples in train= 295 no of low samples in train= 192\n",
            "train feature shape: (486, 69)\n",
            "test feature shape: (162, 69)\n",
            "(486, 4)\n",
            "(162, 4)\n",
            "train size in model function= 486 test size in model function= 162\n",
            "number of unique rows= (486, 5)\n",
            "train size after removing duplicates= 486 test size after removing duplicates= 162\n",
            "Y_test= [1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1.\n",
            " 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1.\n",
            " 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
            " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1.]\n",
            "Y_pred= [0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1.\n",
            " 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.5477279477279478\n",
            "Test accuracy= 0.7098765432098766\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.27      0.28      0.28        32\n",
            "         1.0       0.82      0.82      0.82       130\n",
            "\n",
            "    accuracy                           0.71       162\n",
            "   macro avg       0.55      0.55      0.55       162\n",
            "weighted avg       0.71      0.71      0.71       162\n",
            "\n",
            "data size= 236\n",
            "fold no= 1\n",
            "train data index= 0 --> 176 test data index= 177 ---> 235\n",
            "train_data size= 177 test data size= 59\n",
            "no. of high samples in train= 147 no of low samples in train= 30\n",
            "train feature shape: (177, 69)\n",
            "test feature shape: (59, 69)\n",
            "(177, 4)\n",
            "(59, 4)\n",
            "train size in model function= 177 test size in model function= 59\n",
            "number of unique rows= (177, 5)\n",
            "train size after removing duplicates= 177 test size after removing duplicates= 59\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.4684684684684685\n",
            "Test accuracy= 0.8813559322033898\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         7\n",
            "         1.0       0.88      1.00      0.94        52\n",
            "\n",
            "    accuracy                           0.88        59\n",
            "   macro avg       0.44      0.50      0.47        59\n",
            "weighted avg       0.78      0.88      0.83        59\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size= 149\n",
            "fold no= 1\n",
            "train data index= 0 --> 111 test data index= 112 ---> 149\n",
            "train_data size= 112 test data size= 37\n",
            "no. of high samples in train= 39 no of low samples in train= 73\n",
            "train feature shape: (112, 69)\n",
            "test feature shape: (37, 69)\n",
            "(112, 4)\n",
            "(37, 4)\n",
            "train size in model function= 112 test size in model function= 37\n",
            "number of unique rows= (112, 5)\n",
            "train size after removing duplicates= 112 test size after removing duplicates= 37\n",
            "Y_test= [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "Y_pred= [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.456497175141243\n",
            "Test accuracy= 0.6486486486486487\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.79      0.77      0.78        30\n",
            "         1.0       0.12      0.14      0.13         7\n",
            "\n",
            "    accuracy                           0.65        37\n",
            "   macro avg       0.46      0.45      0.46        37\n",
            "weighted avg       0.67      0.65      0.66        37\n",
            "\n",
            "data size= 47\n",
            "fold no= 1\n",
            "train data index= 0 --> 35 test data index= 36 ---> 47\n",
            "train_data size= 36 test data size= 11\n",
            "no. of high samples in train= 30 no of low samples in train= 6\n",
            "train feature shape: (36, 69)\n",
            "test feature shape: (11, 69)\n",
            "(36, 4)\n",
            "(11, 4)\n",
            "train size in model function= 36 test size in model function= 11\n",
            "number of unique rows= (36, 5)\n",
            "train size after removing duplicates= 36 test size after removing duplicates= 11\n",
            "Y_test= [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.47619047619047616\n",
            "Test accuracy= 0.9090909090909091\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         1\n",
            "         1.0       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.91        11\n",
            "   macro avg       0.45      0.50      0.48        11\n",
            "weighted avg       0.83      0.91      0.87        11\n",
            "\n",
            "data size= 191\n",
            "fold no= 1\n",
            "train data index= 0 --> 143 test data index= 144 ---> 191\n",
            "train_data size= 144 test data size= 47\n",
            "no. of high samples in train= 57 no of low samples in train= 87\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train feature shape: (144, 69)\n",
            "test feature shape: (47, 69)\n",
            "(144, 4)\n",
            "(47, 4)\n",
            "train size in model function= 144 test size in model function= 47\n",
            "number of unique rows= (144, 5)\n",
            "train size after removing duplicates= 144 test size after removing duplicates= 47\n",
            "Y_test= [1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0.]\n",
            "Y_pred= [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.47275641025641024\n",
            "Test accuracy= 0.7021276595744681\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.97      0.82        33\n",
            "         1.0       0.50      0.07      0.12        14\n",
            "\n",
            "    accuracy                           0.70        47\n",
            "   macro avg       0.61      0.52      0.47        47\n",
            "weighted avg       0.65      0.70      0.61        47\n",
            "\n",
            "data size= 121\n",
            "fold no= 1\n",
            "train data index= 0 --> 90 test data index= 91 ---> 121\n",
            "train_data size= 91 test data size= 30\n",
            "no. of high samples in train= 57 no of low samples in train= 34\n",
            "train feature shape: (91, 69)\n",
            "test feature shape: (30, 69)\n",
            "(91, 4)\n",
            "(30, 4)\n",
            "train size in model function= 91 test size in model function= 30\n",
            "number of unique rows= (91, 5)\n",
            "train size after removing duplicates= 91 test size after removing duplicates= 30\n",
            "Y_test= [0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.18918918918918917\n",
            "Test accuracy= 0.23333333333333334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        23\n",
            "         1.0       0.23      1.00      0.38         7\n",
            "\n",
            "    accuracy                           0.23        30\n",
            "   macro avg       0.12      0.50      0.19        30\n",
            "weighted avg       0.05      0.23      0.09        30\n",
            "\n",
            "data size= 184\n",
            "fold no= 1\n",
            "train data index= 0 --> 137 test data index= 138 ---> 183\n",
            "train_data size= 138 test data size= 46\n",
            "no. of high samples in train= 59 no of low samples in train= 79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train feature shape: (137, 69)\n",
            "test feature shape: (46, 69)\n",
            "(137, 4)\n",
            "(46, 4)\n",
            "train size in model function= 137 test size in model function= 46\n",
            "number of unique rows= (137, 5)\n",
            "train size after removing duplicates= 137 test size after removing duplicates= 46\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.4888888888888889\n",
            "Test accuracy= 0.9565217391304348\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         1\n",
            "         1.0       0.98      0.98      0.98        45\n",
            "\n",
            "    accuracy                           0.96        46\n",
            "   macro avg       0.49      0.49      0.49        46\n",
            "weighted avg       0.96      0.96      0.96        46\n",
            "\n",
            "data size= 209\n",
            "fold no= 1\n",
            "train data index= 0 --> 156 test data index= 157 ---> 209\n",
            "train_data size= 157 test data size= 52\n",
            "no. of high samples in train= 149 no of low samples in train= 8\n",
            "train feature shape: (157, 69)\n",
            "test feature shape: (52, 69)\n",
            "(157, 4)\n",
            "(52, 4)\n",
            "train size in model function= 157 test size in model function= 52\n",
            "number of unique rows= (157, 5)\n",
            "train size after removing duplicates= 157 test size after removing duplicates= 52\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.4526315789473684\n",
            "Test accuracy= 0.8269230769230769\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         9\n",
            "         1.0       0.83      1.00      0.91        43\n",
            "\n",
            "    accuracy                           0.83        52\n",
            "   macro avg       0.41      0.50      0.45        52\n",
            "weighted avg       0.68      0.83      0.75        52\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size= 197\n",
            "fold no= 1\n",
            "train data index= 0 --> 147 test data index= 148 ---> 197\n",
            "train_data size= 148 test data size= 49\n",
            "no. of high samples in train= 124 no of low samples in train= 24\n",
            "train feature shape: (147, 69)\n",
            "test feature shape: (49, 69)\n",
            "(147, 4)\n",
            "(49, 4)\n",
            "train size in model function= 147 test size in model function= 49\n",
            "number of unique rows= (147, 5)\n",
            "train size after removing duplicates= 147 test size after removing duplicates= 49\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.4842105263157895\n",
            "Test accuracy= 0.9387755102040817\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         2\n",
            "         1.0       0.96      0.98      0.97        47\n",
            "\n",
            "    accuracy                           0.94        49\n",
            "   macro avg       0.48      0.49      0.48        49\n",
            "weighted avg       0.92      0.94      0.93        49\n",
            "\n",
            "data size= 166\n",
            "fold no= 1\n",
            "train data index= 0 --> 124 test data index= 125 ---> 166\n",
            "train_data size= 125 test data size= 41\n",
            "no. of high samples in train= 111 no of low samples in train= 14\n",
            "train feature shape: (125, 69)\n",
            "test feature shape: (41, 69)\n",
            "(125, 4)\n",
            "(41, 4)\n",
            "train size in model function= 125 test size in model function= 41\n",
            "number of unique rows= (125, 5)\n",
            "train size after removing duplicates= 125 test size after removing duplicates= 41\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.4743589743589744\n",
            "Test accuracy= 0.9024390243902439\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         4\n",
            "         1.0       0.90      1.00      0.95        37\n",
            "\n",
            "    accuracy                           0.90        41\n",
            "   macro avg       0.45      0.50      0.47        41\n",
            "weighted avg       0.81      0.90      0.86        41\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size= 167\n",
            "fold no= 1\n",
            "train data index= 0 --> 125 test data index= 126 ---> 167\n",
            "train_data size= 126 test data size= 41\n",
            "no. of high samples in train= 107 no of low samples in train= 19\n",
            "train feature shape: (126, 69)\n",
            "test feature shape: (41, 69)\n",
            "(126, 4)\n",
            "(41, 4)\n",
            "train size in model function= 126 test size in model function= 41\n",
            "number of unique rows= (126, 5)\n",
            "train size after removing duplicates= 126 test size after removing duplicates= 41\n",
            "Y_test= [0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.3692307692307692\n",
            "Test accuracy= 0.5853658536585366\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        17\n",
            "         1.0       0.59      1.00      0.74        24\n",
            "\n",
            "    accuracy                           0.59        41\n",
            "   macro avg       0.29      0.50      0.37        41\n",
            "weighted avg       0.34      0.59      0.43        41\n",
            "\n",
            "data size= 183\n",
            "fold no= 1\n",
            "train data index= 0 --> "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137 test data index= 138 ---> 183\n",
            "train_data size= 138 test data size= 45\n",
            "no. of high samples in train= 42 no of low samples in train= 96\n",
            "train feature shape: (136, 69)\n",
            "test feature shape: (45, 69)\n",
            "(136, 4)\n",
            "(45, 4)\n",
            "train size in model function= 136 test size in model function= 45\n",
            "number of unique rows= (136, 5)\n",
            "train size after removing duplicates= 136 test size after removing duplicates= 45\n",
            "Y_test= [1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
            "Y_pred= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.37499999999999994\n",
            "Test accuracy= 0.6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      1.00      0.75        27\n",
            "         1.0       0.00      0.00      0.00        18\n",
            "\n",
            "    accuracy                           0.60        45\n",
            "   macro avg       0.30      0.50      0.37        45\n",
            "weighted avg       0.36      0.60      0.45        45\n",
            "\n",
            "data size= 31\n",
            "fold no= 1\n",
            "train data index= 0 --> 23 test data index= 24 ---> 31\n",
            "train_data size= 24 test data size= 7\n",
            "no. of high samples in train= 8 no of low samples in train= 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train feature shape: (24, 69)\n",
            "test feature shape: (7, 69)\n",
            "(24, 4)\n",
            "(7, 4)\n",
            "train size in model function= 24 test size in model function= 7\n",
            "number of unique rows= (24, 5)\n",
            "train size after removing duplicates= 24 test size after removing duplicates= 7\n",
            "Y_test= [1. 1. 1. 1. 0. 1. 0.]\n",
            "Y_pred= [0. 0. 1. 1. 0. 0. 0.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.5714285714285715\n",
            "Test accuracy= 0.5714285714285714\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.40      1.00      0.57         2\n",
            "         1.0       1.00      0.40      0.57         5\n",
            "\n",
            "    accuracy                           0.57         7\n",
            "   macro avg       0.70      0.70      0.57         7\n",
            "weighted avg       0.83      0.57      0.57         7\n",
            "\n",
            "data size= 99\n",
            "fold no= 1\n",
            "train data index= 0 --> 74 test data index= 75 ---> 99\n",
            "train_data size= 75 test data size= 24\n",
            "no. of high samples in train= 32 no of low samples in train= 43\n",
            "train feature shape: (74, 69)\n",
            "test feature shape: (24, 69)\n",
            "(74, 4)\n",
            "(24, 4)\n",
            "train size in model function= 74 test size in model function= 24\n",
            "number of unique rows= (74, 5)\n",
            "train size after removing duplicates= 74 test size after removing duplicates= 24\n",
            "Y_test= [0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
            "Y_pred= [0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.5636363636363636\n",
            "Test accuracy= 0.625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.43      0.38      0.40         8\n",
            "         1.0       0.71      0.75      0.73        16\n",
            "\n",
            "    accuracy                           0.62        24\n",
            "   macro avg       0.57      0.56      0.56        24\n",
            "weighted avg       0.61      0.62      0.62        24\n",
            "\n",
            "data size= 374\n",
            "fold no= 1\n",
            "train data index= 0 --> 280 test data index= 281 ---> 374\n",
            "train_data size= 281 test data size= 93\n",
            "no. of high samples in train= 190 no of low samples in train= 91\n",
            "train feature shape: (280, 69)\n",
            "test feature shape: (93, 69)\n",
            "(280, 4)\n",
            "(93, 4)\n",
            "train size in model function= 280 test size in model function= 93\n",
            "number of unique rows= (280, 5)\n",
            "train size after removing duplicates= 280 test size after removing duplicates= 93\n",
            "Y_test= [0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0.\n",
            " 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.45930232558139533\n",
            "Test accuracy= 0.8494623655913979\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        14\n",
            "         1.0       0.85      1.00      0.92        79\n",
            "\n",
            "    accuracy                           0.85        93\n",
            "   macro avg       0.42      0.50      0.46        93\n",
            "weighted avg       0.72      0.85      0.78        93\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size= 99\n",
            "fold no= 1\n",
            "train data index= 0 --> 74 test data index= 75 ---> 99\n",
            "train_data size= 75 test data size= 24\n",
            "no. of high samples in train= 73 no of low samples in train= 2\n",
            "train feature shape: (74, 69)\n",
            "test feature shape: (24, 69)\n",
            "(74, 4)\n",
            "(24, 4)\n",
            "train size in model function= 74 test size in model function= 24\n",
            "number of unique rows= (74, 5)\n",
            "train size after removing duplicates= 74 test size after removing duplicates= 24\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 1.0\n",
            "Test accuracy= 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      1.00      1.00        24\n",
            "\n",
            "    accuracy                           1.00        24\n",
            "   macro avg       1.00      1.00      1.00        24\n",
            "weighted avg       1.00      1.00      1.00        24\n",
            "\n",
            "data size= 130\n",
            "fold no= 1\n",
            "train data index= 0 --> 97 test data index= 98 ---> 130\n",
            "train_data size= 98 test data size= 32\n",
            "no. of high samples in train= 67 no of low samples in train= 31\n",
            "train feature shape: (97, 69)\n",
            "test feature shape: (32, 69)\n",
            "(97, 4)\n",
            "(32, 4)\n",
            "train size in model function= 97 test size in model function= 32\n",
            "number of unique rows= (97, 5)\n",
            "train size after removing duplicates= 97 test size after removing duplicates= 32\n",
            "Y_test= [0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 0. 0. 1. 1. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.39622641509433965\n",
            "Test accuracy= 0.65625\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00        11\n",
            "         1.0       0.66      1.00      0.79        21\n",
            "\n",
            "    accuracy                           0.66        32\n",
            "   macro avg       0.33      0.50      0.40        32\n",
            "weighted avg       0.43      0.66      0.52        32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size= 36\n",
            "fold no= 1\n",
            "train data index= 0 --> 26 test data index= 27 ---> 35\n",
            "train_data size= 27 test data size= 9\n",
            "no. of high samples in train= 15 no of low samples in train= 12\n",
            "train feature shape: (27, 69)\n",
            "test feature shape: (9, 69)\n",
            "(27, 4)\n",
            "(9, 4)\n",
            "train size in model function= 27 test size in model function= 9\n",
            "number of unique rows= (27, 5)\n",
            "train size after removing duplicates= 27 test size after removing duplicates= 9\n",
            "Y_test= [0. 0. 1. 0. 1. 1. 0. 0. 0.]\n",
            "Y_pred= [0. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.325\n",
            "Test accuracy= 0.3333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.50      0.17      0.25         6\n",
            "         1.0       0.29      0.67      0.40         3\n",
            "\n",
            "    accuracy                           0.33         9\n",
            "   macro avg       0.39      0.42      0.33         9\n",
            "weighted avg       0.43      0.33      0.30         9\n",
            "\n",
            "data size= 45\n",
            "fold no= 1\n",
            "train data index= 0 --> 33 test data index= 34 ---> 45\n",
            "train_data size= 34 test data size= 11\n",
            "no. of high samples in train= 22 no of low samples in train= 12\n",
            "train feature shape: (34, 69)\n",
            "test feature shape: (11, 69)\n",
            "(34, 4)\n",
            "(11, 4)\n",
            "train size in model function= 34 test size in model function= 11\n",
            "number of unique rows= (34, 5)\n",
            "train size after removing duplicates= 34 test size after removing duplicates= 11\n",
            "Y_test= [1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.4210526315789474\n",
            "Test accuracy= 0.7272727272727273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      0.00      0.00         3\n",
            "         1.0       0.73      1.00      0.84         8\n",
            "\n",
            "    accuracy                           0.73        11\n",
            "   macro avg       0.36      0.50      0.42        11\n",
            "weighted avg       0.53      0.73      0.61        11\n",
            "\n",
            "data size= 126\n",
            "fold no= 1\n",
            "train data index= 0 --> 94 test data index= 95 ---> 126\n",
            "train_data size= 95 test data size= 31\n",
            "no. of high samples in train= 77 no of low samples in train= 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train feature shape: (95, 69)\n",
            "test feature shape: (31, 69)\n",
            "(95, 4)\n",
            "(31, 4)\n",
            "train size in model function= 95 test size in model function= 31\n",
            "number of unique rows= (95, 5)\n",
            "train size after removing duplicates= 95 test size after removing duplicates= 31\n",
            "Y_test= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 1.]\n",
            "Y_pred= [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 1. 1. 0.]\n",
            "Train accuracy= 1.0\n",
            "Test f1= 0.5694444444444444\n",
            "Test accuracy= 0.8064516129032258\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.20      0.25         5\n",
            "         1.0       0.86      0.92      0.89        26\n",
            "\n",
            "    accuracy                           0.81        31\n",
            "   macro avg       0.60      0.56      0.57        31\n",
            "weighted avg       0.77      0.81      0.79        31\n",
            "\n",
            "{11: (487, 649, array([0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
            "       1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
            "       1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
            "       1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
            "       1., 0., 0., 1., 1., 0., 1., 1., 1.])), 12: (177, 235, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1.])), 13: (112, 149, array([1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
            "       0., 1., 0.])), 14: (36, 47, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 15: (144, 191, array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), 16: (91, 121, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 17: (138, 183, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 18: (157, 209, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1.])), 19: (148, 197, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 20: (125, 166, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1.])), 22: (126, 167, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1.])), 23: (138, 183, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), 24: (24, 31, array([0., 0., 1., 1., 0., 0., 0.])), 25: (75, 99, array([0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1.])), 26: (281, 374, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1.])), 28: (75, 99, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1.])), 29: (98, 130, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 31: (27, 35, array([0., 1., 0., 1., 1., 1., 1., 1., 1.])), 32: (34, 45, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), 33: (95, 126, array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
            "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.]))}\n"
          ]
        }
      ],
      "source": [
        "# driver code\n",
        "import pickle\n",
        "dic={}\n",
        "for user_no in range(11,34):\n",
        "  common=[]\n",
        "  user_name='user_'+str(format(user_no,'02'))\n",
        "\n",
        "  dirname='Data/FacialData/Amazon/'+user_name+'.csv'\n",
        "\n",
        "  array=pd.read_csv(dirname)\n",
        "  array=array.drop_duplicates(keep='last')\n",
        "  array=array.drop(['FileName',\"TapEmotion\",'NewTarget'],axis=1)\n",
        "  array=array.drop(['SmileValue_ False','SmileValue_ True','EyeglassesValue_ False','SunglassesValue_ False','SunglassesValue_ True',\"GenderValue_ 'Female'\",\"GenderValue_ 'Male'\",\"BeardValue_ False\",\n",
        "                              \"BeardValue_ True\",\"MustacheValue_ False\",\"EyesOpenValue_ False\",\"EyesOpenValue_ True\",\"MouthOpenValue_ False\",\"MouthOpenValue_ True\",\"MustacheValue_ True\",'EyeglassesValue_ True'],axis=1,errors='ignore')  \n",
        "  array=array.drop(['Confidence','BoundingBoxWidth','BoundingBoxHeight','BoundingBoxLeft','BoundingBoxTop','AgeRangeLow','AgeRangeHigh','SmileConfidence', 'EyesOpenConfidence', 'MouthOpenConfidence','EyeglassesConfidence','SunglassesConfidence','GenderConfidence','BeardConfidence','MustacheConfidence','Date'], axis=1,errors='ignore')                          \n",
        "  column_list=list(array.columns)\n",
        "  common=column_list\n",
        "\n",
        "  dirname='Data/Self_reports/Valence/'\n",
        "\n",
        "  for user in [user_no]:  \n",
        "    # read user file\n",
        "    test_user='user_'+str(format(user,'02'))\n",
        "    test_dir=dirname+test_user+'.csv'\n",
        "    if(os.path.isfile(test_dir)):\n",
        "\n",
        "      dataset=pd.read_csv(test_dir)\n",
        "      dataset=dataset.drop_duplicates(keep='last')\n",
        "    else:\n",
        "\n",
        "      continue  \n",
        "\n",
        "    test_data=dataset.values\n",
        "    data_size=test_data.shape[0]  \n",
        "    print(\"data size=\",data_size)\n",
        "    # specify training and testing data size for each iteration of cross-validation\n",
        "    test_data_size=ceil(data_size*0.25)\n",
        "    train_data_size=ceil(data_size*0.75)\n",
        "    start=0\n",
        "    train_data_index=0\n",
        "    test_data_index=0\n",
        "\n",
        "    accu_list=[]\n",
        "    \n",
        "    train_accu=[] \n",
        "    i=1\n",
        "    \n",
        "\n",
        "  \n",
        "    array1=np.array([])\n",
        "\n",
        "    print(\"fold no=\",i)\n",
        "    train_data_index=start+train_data_size\n",
        "    test_data_index=start+train_data_size+test_data_size\n",
        "    print(\"train data index=\",start,\"-->\",train_data_index-1,\"test data index=\",train_data_index,\"--->\",test_data_index-1)\n",
        "    print(\"train_data size=\",test_data[start:train_data_index,:].shape[0],\"test data size=\",test_data[train_data_index:test_data_index,:].shape[0])\n",
        "    train_dataset=test_data[start:train_data_index,:]\n",
        "    test_dataset=test_data[train_data_index:test_data_index,:]\n",
        "    \n",
        "    \n",
        "    # calculate number of high and low samples in the train set\n",
        "    if(test_dataset.shape[0]!=0):\n",
        "      high_train=0\n",
        "      low_train=0\n",
        "      for k in range(train_dataset.shape[0]):\n",
        "            if(train_dataset[k][1]==0):\n",
        "              low_train+=1\n",
        "            elif(train_dataset[k][1]==1):\n",
        "              high_train+=1\n",
        "      print(\"no. of high samples in train=\",high_train,\"no of low samples in train=\",low_train) \n",
        "      if(low_train==0 or high_train==0):\n",
        "        continue\n",
        "      train_feature,test_feature=feature_file_creation(train_dataset,test_dataset,common)\n",
        "      array1=train_dataset\n",
        "      \n",
        "      \n",
        "      print(\"train feature shape:\",train_feature.shape)\n",
        "      print(\"test feature shape:\",test_feature.shape)\n",
        "      # separte targets from features\n",
        "      X_train=train_feature[:,1:train_feature.shape[1]]   \n",
        "      \n",
        "      Y_train=train_feature[:,0]\n",
        "      X_test=test_feature[:,1:test_feature.shape[1]]\n",
        "    \n",
        "      Y_test=test_feature[:,0]\n",
        "      # seperate facial features\n",
        "      new_train=X_train[:,3:X_train.shape[1]]\n",
        "      new_test=X_test[:,3:X_test.shape[1]]\n",
        "      \n",
        "      # do standarization on facial data\n",
        "      \n",
        "      scaler = StandardScaler()\n",
        "      #scaler.fit(X_train)\n",
        "      scaler.fit(new_train)\n",
        "      new_train=scaler.transform(new_train)\n",
        "      new_test=scaler.transform(new_test)\n",
        "      np.set_printoptions(suppress=True)\n",
        "      \n",
        "\n",
        "      \n",
        "      \n",
        "      # reduce dimension of features\n",
        "      \n",
        "      # apply PCA \n",
        "      pca=KernelPCA(n_components=1,kernel='rbf',eigen_solver='arpack',remove_zero_eig=True,random_state=32)\n",
        "      \n",
        "      pca.fit(new_train)\n",
        "      new_train=pca.transform(new_train)\n",
        "      new_test=pca.transform(new_test)\n",
        "      \n",
        "      \n",
        "      \n",
        "\n",
        "      # apply KLDA\n",
        "      # uncomment the below code when KLDA is applied\n",
        "      '''\n",
        "      klda=kda.KDA(n_components=1,kernel='rbf')\n",
        "      new_train=klda.fit_transform(new_train,Y_train)\n",
        "      new_test=klda.transform(new_test)\n",
        "      '''\n",
        "      \n",
        "      # concatenate self-report features and facial features (obtain from feature reduction tool)\n",
        "      trainX_new=np.concatenate((X_train[:,0:3],new_train),axis=1)\n",
        "      testX_new=np.concatenate((X_test[:,0:3],new_test),axis=1)\n",
        "      \n",
        "      print(trainX_new.shape)\n",
        "      print(testX_new.shape)\n",
        "      Y_train=Y_train.reshape(len(Y_train),1)\n",
        "      Y_test=Y_test.reshape(len(Y_test),1)\n",
        "      \n",
        "      \n",
        "      final_train=np.concatenate((Y_train,trainX_new),axis=1)\n",
        "      final_test=np.concatenate((Y_test,testX_new),axis=1)\n",
        "      \n",
        "      \n",
        "      train_score,score,Y_pred=Random_Forest_model(final_train,final_test)  \n",
        "      ################# our info\n",
        "      dic[user_no]=(train_data_index,test_data_index-1,Y_pred)\n",
        "      #################\n",
        "      accu_list.append(score)\n",
        "      \n",
        "      train_accu.append(train_score)\n",
        "\n",
        "      start=start+test_data_size\n",
        "\n",
        "print(dic)        \n",
        "pickle.dump(dic,open(\"selfi/Arousal/prediction_valence\",\"wb\"))\n",
        "    # # print the accuracy     \n",
        "    # print(\"f1 score list=\",accu_list)\n",
        "    # if(len(train_accu)!=0):   \n",
        "    #     print(\"Train f1-score=\",mean(train_accu))    \n",
        "    # if(len(accu_list)!=0):   \n",
        "    #     print(\"Test f1-score=\",mean(accu_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRIIy_IP3ARD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}